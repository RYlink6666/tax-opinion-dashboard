# è·¨å¢ƒç”µå•†ç¨æ”¶æ”¿ç­–èˆ†è®ºå¯è§†åŒ–ç½‘ç«™ â€” å®Œæ•´åˆ†é˜¶æ®µè®¡åˆ’ï¼ˆv2.0ï¼‰

**é¡¹ç›®åç§°**ï¼šè·¨å¢ƒç”µå•†ç¨æ”¶æ”¿ç­–èˆ†è®ºåˆ†æä¸å¯è§†åŒ–å¹³å°  
**ç ”ç©¶å¯¹è±¡**ï¼š2025å¹´6æœˆ-2026å¹´1æœˆ è·¨å¢ƒç”µå•†ç¨æ”¶æ”¿ç­–èˆ†è®ºè¡¨ç°  
**æ ¸å¿ƒäº§å‡º**ï¼šåœ¨çº¿èˆ†è®ºåˆ†æä»ªè¡¨æ¿  
**æ€»å‘¨æœŸ**ï¼š2025å¹´12æœˆ-2026å¹´3æœˆ  
**ä¸»è¦åˆ›æ–°**ï¼šStreamlitå¯è§†åŒ–ç½‘ç«™ + å­¦æœ¯è®ºæ–‡

---

## é¡¹ç›®å…¨è²Œ

```
æ•°æ®é‡‡é›† â†’ LLMåˆ†æ â†’ Streamlitç½‘ç«™ â†’ è®ºæ–‡æ’°å†™
  (å·²æœ‰)    (12.10-30)   (1.1-31)      (2.1-3.31)
```

---

## ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®å‡†å¤‡æœŸï¼ˆ2025å¹´12æœˆ10-15æ—¥ï¼‰

### é˜¶æ®µç›®æ ‡
- âœ“ å®Œæˆçˆ¬è™«éƒ¨ç½²ï¼ˆæˆ–ç¡®è®¤å·²æœ‰æ•°æ®ï¼‰
- âœ“ é‡‡é›†/æ•´ç†5000+æ¡åŸå§‹èˆ†è®ºæ•°æ®
- âœ“ æ•°æ®æ¸…æ´ã€å»é‡ã€æ ¼å¼åŒ–
- âœ“ å‡†å¤‡JSONè¾“å…¥æ–‡ä»¶

### å…·ä½“ä»»åŠ¡

#### 1.1 æ•°æ®æºç¡®è®¤ï¼ˆ12æœˆ10æ—¥ï¼‰
```
ç¡®è®¤é¡¹ï¼š
â–¡ 5000æ¡èˆ†è®ºæ•°æ®ä½ç½®åœ¨å“ªï¼Ÿ
â–¡ æ•°æ®æ¥æºï¼šå¾®åš/çŸ¥ä¹/å°çº¢ä¹¦çš„åˆ†å¸ƒï¼Ÿ
â–¡ æ—¶é—´èŒƒå›´ï¼šæ˜¯å¦è¦†ç›–2025å¹´6æœˆ-12æœˆï¼Ÿ
â–¡ æ–‡ä»¶æ ¼å¼ï¼šTXT/CSV/JSONï¼Ÿ
â–¡ ç¼–ç ï¼šUTF-8?
â–¡ ç¼ºå¤±é¡¹ï¼šæ˜¯å¦æœ‰å‘å¸ƒæ—¶é—´/å¹³å°/ä½œè€…ä¿¡æ¯ï¼Ÿ

å¦‚æœæ•°æ®è¿˜åœ¨çˆ¬è™«é˜¶æ®µï¼ŒæŒ‰åŸæœ‰è®¡åˆ’å®Œæˆï¼›
å¦‚æœæ•°æ®å·²æœ‰ï¼Œç›´æ¥è¿›å…¥1.2æ­¥éª¤ã€‚
```

#### 1.2 æ•°æ®æ¸…æ´ï¼ˆ12æœˆ11-13æ—¥ï¼‰

```python
# æ¸…æ´æ ‡å‡†ï¼š
â–¡ å»é‡ï¼šç›¸åŒæˆ–æç›¸ä¼¼å†…å®¹åªä¿ä¸€æ¡
â–¡ è¿‡æ»¤ï¼šå¹¿å‘Š/æœºå™¨äººè¯„è®º/æ— æ„ä¹‰å†…å®¹
â–¡ æˆªæ–­ï¼šè¶…é•¿æ–‡æœ¬æˆªè‡³500å­—ç¬¦
â–¡ ç¼–ç ï¼šç»Ÿä¸€ä¸ºUTF-8
â–¡ æ ¼å¼ï¼šå‡†å¤‡ä¸º opinions_clean_5000.txtï¼ˆæ¯è¡Œä¸€æ¡ï¼‰

# Pythonæ¸…æ´è„šæœ¬ç¤ºä¾‹ï¼š
import pandas as pd

df = pd.read_csv('opinions_raw.csv')

# å»é‡
df = df.drop_duplicates(subset=['text'])

# è¿‡æ»¤çŸ­æ–‡æœ¬
df = df[df['text'].str.len() >= 10]

# ç»Ÿä¸€ç¼–ç å¹¶ä¿å­˜
with open('opinions_clean_5000.txt', 'w', encoding='utf-8') as f:
    for text in df['text']:
        f.write(text + '\n')

print(f"âœ“ æ¸…æ´å®Œæˆï¼š{len(df)} æ¡")
```

#### 1.3 æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆ12æœˆ14-15æ—¥ï¼‰
```
æ£€æŸ¥æ¸…å•ï¼š
â–¡ æ€»æ¡æ•°ï¼šâ‰¥4800æ¡ï¼ˆå…è®¸10%æŸè€—ï¼‰
â–¡ æ–‡ä»¶å¤§å°ï¼š2-3MB
â–¡ å¹³å‡é•¿åº¦ï¼š100-300å­—ç¬¦
â–¡ æ—¶é—´è¦†ç›–ï¼šâ‰¥6ä¸ªæœˆ
â–¡ å¹³å°åˆ†å¸ƒï¼šå¤šä¸ªå¹³å°æ··åˆ
â–¡ è´¨é‡æŠ½æ ·ï¼šéšæœºæŠ½10æ¡äººå·¥æ£€æŸ¥
```

### é˜¶æ®µäº§å‡º
- âœ… opinions_clean_5000.txtï¼ˆ5000æ¡æ¸…æ´æ–‡æœ¬ï¼‰
- âœ… æ•°æ®è´¨é‡æŠ¥å‘Š
- âœ… æ•°æ®ç»Ÿè®¡æ±‡æ€»

---

## ç¬¬äºŒé˜¶æ®µï¼šæ•°æ®åˆ†ææœŸï¼ˆ2025å¹´12æœˆ16-30æ—¥ï¼‰

### é˜¶æ®µç›®æ ‡
- âœ“ ç”¨æ™ºè°±æ¸…è¨€APIè¿›è¡ŒLLMåˆ†æ
- âœ“ å®Œæˆ5ç»´åº¦ç»“æ„åŒ–åˆ†ç±»
- âœ“ ç”Ÿæˆanalysis_results_5000.json
- âœ“ é›¶æˆæœ¬å®Œæˆï¼ˆç”¨å·²æœ‰2000ä¸‡tokenï¼‰

### å…·ä½“ä»»åŠ¡

#### 2.1 ç¯å¢ƒæ­å»ºï¼ˆ12æœˆ16æ—¥ï¼‰

```bash
# 1. è·å–æ™ºè°±APIå¯†é’¥ï¼ˆ2åˆ†é’Ÿï¼‰
è®¿é—®ï¼šhttps://www.bigmodel.cn/console/overview
ç™»å½• â†’ "APIå¯†é’¥" â†’ "æ–°å¢å¯†é’¥" â†’ å¤åˆ¶

# 2. åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒï¼ˆ3åˆ†é’Ÿï¼‰
python -m venv opinion_env
source opinion_env/bin/activate  # Windows: opinion_env\Scripts\activate

# 3. å®‰è£…ä¾èµ–ï¼ˆ2åˆ†é’Ÿï¼‰
pip install zhipu-ai pandas python-dotenv

# 4. åˆ›å»º .env æ–‡ä»¶
ZHIPU_API_KEY=sk-ä½ çš„å¯†é’¥
```

#### 2.2 æ ·æœ¬æµ‹è¯•ï¼ˆ12æœˆ17-18æ—¥ï¼‰

```
ç›®æ ‡ï¼šç”¨100æ¡æ ·æœ¬éªŒè¯ç²¾åº¦â‰¥85%

æ­¥éª¤ï¼š
1ï¸âƒ£ æŠ½å–100æ¡æ ·æœ¬ â†’ sample_100.txt
2ï¸âƒ£ è¿è¡Œ llm_analyzer.py åˆ†æ
3ï¸âƒ£ äººå·¥æ ‡æ³¨20æ¡è¿›è¡Œå¯¹æ¯”
4ï¸âƒ£ è®¡ç®—åŒ¹é…ç‡

å¦‚æœâ‰¥85% â†’ ç»§ç»­å…¨é‡å¤„ç†
å¦‚æœ<85%  â†’ è°ƒæ•´Prompté‡è¯•
```

#### 2.3 å…¨é‡å¤„ç†ï¼ˆ12æœˆ19-26æ—¥ï¼‰

```python
# main.py - å®Œæ•´çš„LLMåˆ†æè„šæœ¬
from zhipu_ai.client import ZhipuAI
import json
import time

client = ZhipuAI(api_key="ä½ çš„å¯†é’¥")

SYSTEM_PROMPT = """ä½ æ˜¯ä¸“ä¸šçš„è·¨å¢ƒç”µå•†ç¨æ”¶èˆ†è®ºåˆ†æç³»ç»Ÿ...
[è§04æ–‡æ¡£çš„å®Œæ•´Prompt]
"""

def analyze(text):
    response = client.chat.completions.create(
        model="glm-4-flash",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": f"åˆ†æï¼š{text}"}
        ]
    )
    return json.loads(response.choices[0].message.content)

# è¯»å–æ•°æ®
with open('opinions_clean_5000.txt', 'r', encoding='utf-8') as f:
    opinions = [line.strip() for line in f.readlines()]

# åˆ†æ
results = []
for i, opinion in enumerate(opinions):
    print(f"[{i+1}/{len(opinions)}]", end='\r')
    result = analyze(opinion)
    result['source_text'] = opinion
    results.append(result)
    
    if (i + 1) % 10 == 0:
        time.sleep(1)  # é¿å…é™æµ

# ä¿å­˜
with open('analysis_results_5000.json', 'w', encoding='utf-8') as f:
    json.dump({"total": len(results), "results": results}, f, ensure_ascii=False, indent=2)
```

#### 2.4 è´¨é‡éªŒè¯ï¼ˆ12æœˆ27-30æ—¥ï¼‰

```
éªŒè¯é¡¹ï¼š
â–¡ æ–‡ä»¶å¤§å°ï¼š>50MB
â–¡ è®°å½•æ•°ï¼š=5000
â–¡ å­—æ®µå®Œæ•´ï¼šsentiment, pattern, risk_categoryç­‰
â–¡ ç½®ä¿¡åº¦åˆ†å¸ƒï¼šå¹³å‡â‰¥0.80
â–¡ é”™è¯¯ç‡ï¼š<3%

è¾“å‡ºï¼šquality_report_5000.json
```

### é˜¶æ®µäº§å‡º
- âœ… analysis_results_5000.jsonï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
- âœ… è´¨é‡éªŒè¯æŠ¥å‘Š
- âœ… æ ·æœ¬ç²¾åº¦è¯„ä¼°

---

## ç¬¬ä¸‰é˜¶æ®µï¼šç½‘ç«™å¼€å‘ä¸éƒ¨ç½²ï¼ˆ2026å¹´1æœˆ1-31æ—¥ï¼‰

### é˜¶æ®µç›®æ ‡
- âœ“ æ­å»ºå®Œæ•´Streamlitå¯è§†åŒ–ç½‘ç«™
- âœ“ å®ç°7ä¸ªæ ¸å¿ƒåŠŸèƒ½é¡µé¢
- âœ“ éƒ¨ç½²åˆ°Streamlit Cloudï¼ˆå…è´¹ï¼‰
- âœ“ è·å¾—åœ¨çº¿å¯è®¿é—®çš„ä»ªè¡¨æ¿ URL

### å…·ä½“ä»»åŠ¡

#### 3.1 é¡¹ç›®åˆå§‹åŒ–ï¼ˆ1æœˆ1-2æ—¥ï¼Œ2å°æ—¶ï¼‰

```
åˆ›å»ºGitHubä»“åº“ + æœ¬åœ°é¡¹ç›®ç»“æ„ï¼š

streamlit_app/
â”œâ”€â”€ main.py                    # é¦–é¡µå…¥å£
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_ğŸ“Š_Overview.py       # è¯¦ç»†æ€»è§ˆ
â”‚   â”œâ”€â”€ 2_ğŸ”„_Modes.py          # 6å¤§æ¨¡å¼åˆ†æ
â”‚   â”œâ”€â”€ 3_âš ï¸_Risks.py          # é£é™©åˆ†æ
â”‚   â”œâ”€â”€ 4_ğŸ“ˆ_Behaviors.py      # è¡Œä¸ºå“åº”
â”‚   â”œâ”€â”€ 5_ğŸ·ï¸_Keywords.py       # å…³é”®è¯
â”‚   â”œâ”€â”€ 6_ğŸ“‹_Articles.py       # æ•°æ®è¯¦è§ˆ
â”‚   â””â”€â”€ 7_â„¹ï¸_About.py          # å…³äºé¡¹ç›®
â”œâ”€â”€ data/
â”‚   â””â”€â”€ analysis_results_5000.json
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ data_loader.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml
â””â”€â”€ README.md

æ“ä½œï¼š
1. mkdir streamlit_app && cd streamlit_app
2. git init
3. å¤åˆ¶ä¸‹é¢çš„ä»£ç æ¡†æ¶
4. åˆ›å»ºrequirements.txt
5. git push origin main
```

#### 3.2 æ ¸å¿ƒä»£ç å¼€å‘ï¼ˆ1æœˆ3-22æ—¥ï¼Œ15å¤©ï¼‰

**main.py** - é¦–é¡µæ€»è§ˆï¼ˆ1å¤©ï¼‰
```python
import streamlit as st
import pandas as pd
import plotly.express as px
import json

st.set_page_config(
    page_title="è·¨å¢ƒç”µå•†èˆ†è®ºåˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# åŠ è½½æ•°æ®ï¼ˆç¼“å­˜ï¼‰
@st.cache_data
def load_data():
    with open('data/analysis_results_5000.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return pd.DataFrame(data['results'])

df = load_data()

# æ ‡é¢˜
st.title("ğŸ¯ è·¨å¢ƒç”µå•†ç¨æ”¶èˆ†è®ºåˆ†æä»ªè¡¨æ¿")
st.markdown("åŸºäº5000æ¡èˆ†è®ºçš„LLMç»“æ„åŒ–åˆ†æ | 2025å¹´6æœˆ-12æœˆ")

# å…³é”®æŒ‡æ ‡
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("æ€»èˆ†è®ºæ•°", f"{len(df):,}")
with col2:
    neg = len(df[df['sentiment']=='negative']) / len(df) * 100
    st.metric("è´Ÿé¢å æ¯”", f"{neg:.1f}%")
with col3:
    critical = len(df[df['risk_severity']=='Critical'])
    st.metric("Criticalé£é™©", f"{critical}")
with col4:
    compliance = len(df[df['behavioral_intent']=='Compliance'])
    st.metric("åˆè§„å€¾å‘", f"{compliance}")

st.markdown("---")

# æƒ…æ„Ÿåˆ†å¸ƒ
col1, col2 = st.columns(2)
with col1:
    sentiment = df['sentiment'].value_counts()
    fig = px.pie(values=sentiment.values, names=sentiment.index, title="æƒ…æ„Ÿåˆ†å¸ƒ")
    st.plotly_chart(fig, use_container_width=True)

with col2:
    pattern = df['pattern'].value_counts().head(6)
    fig = px.bar(x=pattern.values, y=pattern.index, orientation='h', title="ä¸»è¦æ¨¡å¼ï¼ˆTop 6ï¼‰")
    st.plotly_chart(fig, use_container_width=True)

# é£é™©æ’è¡Œ
st.subheader("âš ï¸ é£é™©ç±»å‹æ’å")
risk = df['risk_category'].value_counts().head(8)
fig = px.bar(x=risk.values, y=risk.index, orientation='h', title="é£é™©åˆ†å¸ƒï¼ˆTop 8ï¼‰")
st.plotly_chart(fig, use_container_width=True)

# å…³é”®æ´å¯Ÿ
st.subheader("ğŸ’¡ å…³é”®å‘ç°")
for i, insight in enumerate(df['key_insight'].dropna().unique()[:5], 1):
    st.info(f"{i}. {insight}")
```

**pages/1_ğŸ“Š_Overview.py** - è¯¦ç»†æ€»è§ˆï¼ˆ1å¤©ï¼‰
```python
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import json

st.set_page_config(page_title="è¯¦ç»†æ€»è§ˆ", layout="wide")

@st.cache_data
def load_data():
    with open('data/analysis_results_5000.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return pd.DataFrame(data['results'])

df = load_data()

st.title("ğŸ“Š è¯¦ç»†æ•°æ®æ€»è§ˆ")

# å¤šç»´åº¦ç»Ÿè®¡
col1, col2, col3 = st.columns(3)

with col1:
    st.metric("æƒ…æ„Ÿåˆ†å¸ƒ", df['sentiment'].nunique(), "ç»´åº¦")
with col2:
    st.metric("è¯†åˆ«æ¨¡å¼", df['pattern'].nunique(), "ç§")
with col3:
    st.metric("é£é™©ç±»å‹", df['risk_category'].nunique(), "ç§")

st.markdown("---")

# äº¤å‰åˆ†æï¼šæ¨¡å¼ Ã— æƒ…æ„Ÿ
st.subheader("æ¨¡å¼ Ã— æƒ…æ„Ÿäº¤å‰åˆ†æ")
cross = pd.crosstab(df['pattern'], df['sentiment'])
fig = go.Figure(data=[
    go.Bar(name=col, x=cross.index, y=cross[col])
    for col in cross.columns
])
fig.update_layout(barmode='group', title="å„æ¨¡å¼çš„æƒ…æ„Ÿåˆ†å¸ƒ")
st.plotly_chart(fig, use_container_width=True)

# äº¤å‰åˆ†æï¼šæ¨¡å¼ Ã— é£é™©
st.subheader("æ¨¡å¼ Ã— é£é™©çƒ­åŠ›å›¾")
cross2 = pd.crosstab(df['pattern'], df['risk_category'])
fig = go.Figure(data=go.Heatmap(z=cross2.values, x=cross2.columns, y=cross2.index))
st.plotly_chart(fig, use_container_width=True)

# è¡Œä¸ºåˆ†å¸ƒ
st.subheader("è¡Œä¸ºå€¾å‘åˆ†å¸ƒ")
behavior = df['behavioral_intent'].value_counts()
fig = px.bar(x=behavior.index, y=behavior.values, title="ä¼ä¸šè¡Œä¸ºå“åº”")
st.plotly_chart(fig, use_container_width=True)
```

**pages/2_ğŸ”„_Modes.py** - 6å¤§æ¨¡å¼åˆ†æï¼ˆ2å¤©ï¼‰
```python
import streamlit as st
import pandas as pd
import plotly.express as px
import json

st.set_page_config(page_title="æ¨¡å¼åˆ†æ", layout="wide")

@st.cache_data
def load_data():
    with open('data/analysis_results_5000.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return pd.DataFrame(data['results'])

df = load_data()

st.title("ğŸ”„ 6å¤§äº¤æ˜“æ¨¡å¼æ·±åº¦åˆ†æ")

modes = ['0110', '9610', '9710', '9810', '1039', 'Temu']
tabs = st.tabs(modes)

for idx, mode in enumerate(modes):
    with tabs[idx]:
        mode_df = df[df['pattern'] == mode]
        
        if len(mode_df) == 0:
            st.warning(f"æ²¡æœ‰{mode}çš„æ•°æ®")
            continue
        
        # æ¨¡å¼ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("èˆ†è®ºæ•°", len(mode_df))
        with col2:
            pct = len(mode_df) / len(df) * 100
            st.metric("å æ¯”", f"{pct:.1f}%")
        with col3:
            neg = len(mode_df[mode_df['sentiment']=='negative']) / len(mode_df) * 100
            st.metric("è´Ÿé¢ç‡", f"{neg:.1f}%")
        with col4:
            main_risk = mode_df['risk_category'].value_counts().index[0]
            st.metric("ä¸»è¦é£é™©", main_risk)
        
        st.markdown("---")
        
        # è¯¥æ¨¡å¼çš„åˆ†æ
        col1, col2 = st.columns(2)
        
        with col1:
            risk = mode_df['risk_category'].value_counts()
            fig = px.bar(x=risk.values, y=risk.index, orientation='h', 
                        title=f"{mode} - é£é™©ç±»å‹")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            behavior = mode_df['behavioral_intent'].value_counts()
            fig = px.pie(values=behavior.values, names=behavior.index,
                        title=f"{mode} - è¡Œä¸ºå€¾å‘")
            st.plotly_chart(fig, use_container_width=True)
        
        # å…¸å‹æ¡ˆä¾‹
        st.subheader(f"ğŸ“Œ {mode} å…¸å‹æ¡ˆä¾‹")
        samples = mode_df.nlargest(5, 'sentiment_confidence')
        
        for _, row in samples.iterrows():
            with st.expander(f"ã€{row['sentiment']}ã€‘{row['source_text'][:50]}..."):
                st.write(f"ğŸ“ **åŸæ–‡**ï¼š{row['source_text']}")
                st.write(f"ğŸ˜Š **æƒ…æ„Ÿ**ï¼š{row['sentiment']} (ç½®ä¿¡åº¦ {row['sentiment_confidence']:.2%})")
                st.write(f"âš ï¸ **é£é™©**ï¼š{row['risk_category']} (ä¸¥é‡æ€§ {row['risk_severity']})")
                st.write(f"ğŸ¯ **è¡Œä¸º**ï¼š{row['behavioral_intent']}")
                st.write(f"ğŸ’¡ **æ´å¯Ÿ**ï¼š{row['key_insight']}")
```

**pages/3_âš ï¸_Risks.py** - é£é™©åˆ†æï¼ˆ2å¤©ï¼‰
```python
import streamlit as st
import pandas as pd
import plotly.express as px
import json

st.set_page_config(page_title="é£é™©åˆ†æ", layout="wide")

@st.cache_data
def load_data():
    with open('data/analysis_results_5000.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return pd.DataFrame(data['results'])

df = load_data()

st.title("âš ï¸ é£é™©ç±»å‹æ·±åº¦åˆ†æ")

# é£é™©æ’è¡Œ
st.subheader("é£é™©ä¸¥é‡æ€§æ’åº")
severity_order = {'Critical': 4, 'High': 3, 'Medium': 2, 'Low': 1}
risk_severity = df.groupby('risk_category')['risk_severity'].apply(
    lambda x: x.map(severity_order).mean()
).sort_values(ascending=False)

fig = px.bar(x=risk_severity.values, y=risk_severity.index, orientation='h',
            title="é£é™©å¹³å‡ä¸¥é‡ç¨‹åº¦", color=risk_severity.values,
            color_continuous_scale='Reds')
st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# æ¨¡å¼Ã—é£é™©çƒ­åŠ›å›¾
st.subheader("äº¤æ˜“æ¨¡å¼ Ã— é£é™©ç±»å‹çƒ­åŠ›å›¾")
heatmap = pd.crosstab(df['pattern'], df['risk_category'])
fig = go.Figure(data=go.Heatmap(z=heatmap.values, x=heatmap.columns, y=heatmap.index,
                                colorscale='Reds'))
st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# å„é£é™©ç±»å‹çš„è¯¦ç»†åˆ†æ
st.subheader("é£é™©ç±»å‹è¯¦æƒ…")
risk_types = df['risk_category'].unique()

for risk in sorted(risk_types):
    risk_df = df[df['risk_category'] == risk]
    
    with st.expander(f"**{risk}** (n={len(risk_df)})"):
        col1, col2 = st.columns(2)
        
        with col1:
            sentiment = risk_df['sentiment'].value_counts()
            fig = px.pie(values=sentiment.values, names=sentiment.index,
                        title=f"{risk} - æƒ…æ„Ÿåˆ†å¸ƒ")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            severity = risk_df['risk_severity'].value_counts()
            fig = px.bar(x=severity.index, y=severity.values,
                        title=f"{risk} - ä¸¥é‡ç¨‹åº¦")
            st.plotly_chart(fig, use_container_width=True)
        
        # ä»£è¡¨æ€§èˆ†è®º
        st.write("**ä»£è¡¨æ€§èˆ†è®º**ï¼ˆæŒ‰ç½®ä¿¡åº¦æ’åºï¼‰ï¼š")
        reps = risk_df.nlargest(3, 'risk_confidence')
        for _, row in reps.iterrows():
            st.write(f"- {row['source_text'][:100]}...")
```

**pages/4_ğŸ“ˆ_Behaviors.py** - è¡Œä¸ºå“åº”ï¼ˆ1.5å¤©ï¼‰
```python
import streamlit as st
import pandas as pd
import plotly.express as px
import json

st.set_page_config(page_title="è¡Œä¸ºåˆ†æ", layout="wide")

@st.cache_data
def load_data():
    with open('data/analysis_results_5000.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return pd.DataFrame(data['results'])

df = load_data()

st.title("ğŸ“ˆ ä¼ä¸šè¡Œä¸ºå“åº”åˆ†æ")

# è¡Œä¸ºåˆ†å¸ƒ
st.subheader("ä¼ä¸šè¡Œä¸ºå€¾å‘åˆ†å¸ƒ")
behavior = df['behavioral_intent'].value_counts()
fig = px.bar(x=behavior.index, y=behavior.values, title="5ç§è¡Œä¸ºçš„åˆ†å¸ƒ",
            color=behavior.values, color_continuous_scale='Viridis')
st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# è¡Œä¸ºÃ—æƒ…æ„Ÿ
st.subheader("è¡Œä¸º Ã— æƒ…æ„Ÿäº¤å‰åˆ†æ")
cross = pd.crosstab(df['behavioral_intent'], df['sentiment'])
fig = go.Figure(data=[
    go.Bar(name=col, x=cross.index, y=cross[col])
    for col in cross.columns
])
fig.update_layout(barmode='group', title="ä¸åŒè¡Œä¸ºçš„æƒ…æ„Ÿå€¾å‘")
st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# èº«ä»½ç‰¹å¾åˆ†æ
st.subheader("çº³ç¨äººèº«ä»½åˆ†æ")
col1, col2, col3 = st.columns(3)

identity = df['taxpayer_identity'].value_counts()
with col1:
    fig = px.pie(values=identity.values, names=identity.index, 
                title="èº«ä»½åˆ†å¸ƒ")
    st.plotly_chart(fig, use_container_width=True)

# èº«ä»½Ã—è¡Œä¸º
with col2:
    cross = pd.crosstab(df['taxpayer_identity'], df['behavioral_intent'])
    fig = px.bar(x=cross.index, y=[cross[col].sum() for col in cross.columns],
                title="èº«ä»½-è¡Œä¸ºåˆ†å¸ƒ")
    st.plotly_chart(fig, use_container_width=True)

# å…³é”®å‘ç°
st.markdown("---")
st.subheader("ğŸ’¡ è¡Œä¸ºæ´å¯Ÿ")
insights = {
    'Compliance': f"{len(df[df['behavioral_intent']=='Compliance'])} æ¡ - ä¼ä¸šä¸»åŠ¨å¯»æ±‚åˆè§„",
    'Mode_Switch': f"{len(df[df['behavioral_intent']=='Mode_Switch'])} æ¡ - è€ƒè™‘è½¬æ¢äº¤æ˜“æ¨¡å¼",
    'Help_Seeking': f"{len(df[df['behavioral_intent']=='Help_Seeking'])} æ¡ - ç§¯æå¯»æ±‚è§£å†³æ–¹æ¡ˆ",
    'Wait_and_See': f"{len(df[df['behavioral_intent']=='Wait_and_See'])} æ¡ - è§‚æœ›æ”¿ç­–è¿›å±•",
    'No_Action': f"{len(df[df['behavioral_intent']=='No_Action'])} æ¡ - ä»…è®¨è®ºæ— è¡ŒåŠ¨",
}
for behavior, insight in insights.items():
    st.info(insight)
```

**pages/5_ğŸ·ï¸_Keywords.py** - å…³é”®è¯åˆ†æï¼ˆ1.5å¤©ï¼‰
```python
import streamlit as st
import pandas as pd
import plotly.express as px
from collections import Counter
import json
import re

st.set_page_config(page_title="å…³é”®è¯", layout="wide")

@st.cache_data
def load_data():
    with open('data/analysis_results_5000.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return pd.DataFrame(data['results'])

df = load_data()

st.title("ğŸ·ï¸ å…³é”®è¯åˆ†æ")

# æå–å…³é”®è¯
def extract_keywords(texts, top_n=50):
    words = []
    for text in texts:
        # ç®€å•åˆ†è¯ï¼šæŒ‰é•¿åº¦>2çš„è¯æå–
        tokens = re.findall(r'[\u4e00-\u9fff]{2,}', text)
        words.extend(tokens)
    counter = Counter(words)
    return counter.most_common(top_n)

keywords = extract_keywords(df['source_text'], top_n=100)
kw_df = pd.DataFrame(keywords, columns=['word', 'frequency'])

# è¯äº‘
st.subheader("ğŸ“Š è¯é¢‘åˆ†å¸ƒ")
fig = px.bar(kw_df.head(30), x='word', y='frequency', title="é«˜é¢‘è¯æ±‡ï¼ˆTop 30ï¼‰")
st.plotly_chart(fig, use_container_width=True)

# å…³é”®è¯è¡¨
st.subheader("ğŸ”¤ å…³é”®è¯è¯¦ç»†è¡¨")
st.dataframe(kw_df.head(50), use_container_width=True)

# è¯è¯­ä¸é£é™©çš„å…³è”
st.markdown("---")
st.subheader("âš ï¸ å…³é”®è¯-é£é™©å…³è”")

risk_types = df['risk_category'].unique()
for risk in sorted(risk_types)[:5]:  # æ˜¾ç¤ºå‰5ä¸ªé£é™©
    risk_texts = df[df['risk_category']==risk]['source_text']
    risk_kws = extract_keywords(risk_texts, top_n=10)
    
    with st.expander(f"**{risk}** é«˜é¢‘è¯æ±‡"):
        risk_kw_df = pd.DataFrame(risk_kws, columns=['word', 'frequency'])
        st.dataframe(risk_kw_df, use_container_width=True)
```

**pages/6_ğŸ“‹_Articles.py** - æ•°æ®è¯¦è§ˆï¼ˆ2å¤©ï¼‰
```python
import streamlit as st
import pandas as pd
import json

st.set_page_config(page_title="æ•°æ®è¯¦è§ˆ", layout="wide")

@st.cache_data
def load_data():
    with open('data/analysis_results_5000.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return pd.DataFrame(data['results'])

df = load_data()

st.title("ğŸ“‹ èˆ†è®ºæ•°æ®è¯¦è§ˆ")

# ç­›é€‰é¢æ¿
st.subheader("ğŸ” å¤šç»´åº¦ç­›é€‰")
col1, col2, col3, col4 = st.columns(4)

with col1:
    sentiment_filter = st.multiselect("æƒ…æ„Ÿ", ['positive', 'negative', 'neutral'], default=None)
with col2:
    pattern_filter = st.multiselect("æ¨¡å¼", df['pattern'].unique(), default=None)
with col3:
    risk_filter = st.multiselect("é£é™©", df['risk_category'].unique(), default=None)
with col4:
    behavior_filter = st.multiselect("è¡Œä¸º", df['behavioral_intent'].unique(), default=None)

# å…³é”®è¯æœç´¢
search_text = st.text_input("ğŸ” å…³é”®è¯æœç´¢")

# åº”ç”¨ç­›é€‰
filtered_df = df.copy()

if sentiment_filter:
    filtered_df = filtered_df[filtered_df['sentiment'].isin(sentiment_filter)]
if pattern_filter:
    filtered_df = filtered_df[filtered_df['pattern'].isin(pattern_filter)]
if risk_filter:
    filtered_df = filtered_df[filtered_df['risk_category'].isin(risk_filter)]
if behavior_filter:
    filtered_df = filtered_df[filtered_df['behavioral_intent'].isin(behavior_filter)]
if search_text:
    filtered_df = filtered_df[filtered_df['source_text'].str.contains(search_text, na=False)]

st.info(f"ğŸ“Š æ‰¾åˆ° {len(filtered_df)}/{len(df)} æ¡èˆ†è®º")

# ç»“æœåˆ†é¡µæ˜¾ç¤º
page_size = 20
page = st.slider("é¡µç ", 1, (len(filtered_df)-1)//page_size + 1)
start_idx = (page - 1) * page_size
end_idx = start_idx + page_size

st.subheader(f"èˆ†è®ºåˆ—è¡¨ï¼ˆ{start_idx+1}-{min(end_idx, len(filtered_df))}ï¼‰")

for idx, (_, row) in enumerate(filtered_df.iloc[start_idx:end_idx].iterrows()):
    with st.expander(f"ã€{row['sentiment'].upper()}ã€‘{row['source_text'][:50]}..."):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**åŸæ–‡**ï¼š{row['source_text']}")
            st.write(f"**æƒ…æ„Ÿ**ï¼š{row['sentiment']} ({row['sentiment_confidence']:.0%})")
            st.write(f"**æ¨¡å¼**ï¼š{row['pattern']}")
        
        with col2:
            st.write(f"**é£é™©**ï¼š{row['risk_category']}")
            st.write(f"**ä¸¥é‡æ€§**ï¼š{row['risk_severity']}")
            st.write(f"**èº«ä»½**ï¼š{row['taxpayer_identity']}")
            st.write(f"**è¡Œä¸º**ï¼š{row['behavioral_intent']}")
        
        st.write(f"**æ´å¯Ÿ**ï¼š{row['key_insight']}")
        st.divider()
```

**pages/7_â„¹ï¸_About.py** - å…³äºé¡¹ç›®ï¼ˆ0.5å¤©ï¼‰
```python
import streamlit as st

st.set_page_config(page_title="å…³äº", layout="wide")

st.title("â„¹ï¸ å…³äºæœ¬é¡¹ç›®")

st.markdown("""
## é¡¹ç›®èƒŒæ™¯

æœ¬å¹³å°åˆ†æäº†2025å¹´6æœˆ-12æœˆé—´ï¼Œè·¨å¢ƒç”µå•†ä¼ä¸šå¯¹ä¸­å›½ç¨æ”¶æ”¿ç­–æ”¹é©çš„èˆ†è®ºå“åº”ã€‚

é€šè¿‡LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰çš„è‡ªåŠ¨åŒ–åˆ†æï¼Œæˆ‘ä»¬ä»5000æ¡å¾®åšã€çŸ¥ä¹ã€å°çº¢ä¹¦ç­‰å¹³å°çš„èˆ†è®ºä¸­ï¼Œæå–äº†ç»“æ„åŒ–çš„æ”¿ç­–å“åº”ä¿¡æ¯ã€‚

## åˆ†æç»´åº¦

### 1ï¸âƒ£ æƒ…æ„Ÿååº” (Sentiment)
- **Positive**ï¼šæ”¯æŒæ”¿ç­–ã€æ¥å—ç°çŠ¶
- **Negative**ï¼šåå¯¹ã€ç„¦è™‘ã€å›°æƒ‘
- **Neutral**ï¼šä¸­ç«‹ã€çº¯ä¿¡æ¯é™ˆè¿°

### 2ï¸âƒ£ ä¸šåŠ¡æ¨¡å¼ (Pattern)
- **0110**ï¼šä¼ ç»Ÿå¤–è´¸+é¦™æ¸¯å…¬å¸
- **9610**ï¼šB2Cå°åŒ…è£¹é›¶å”®
- **9710**ï¼šB2Bç›´æ¥å‡ºå£
- **9810**ï¼šæµ·å¤–ä»“æ¨¡å¼
- **1039**ï¼šå¸‚åœºé‡‡è´­
- **Temu**ï¼šå¹³å°å…¨æ‰˜ç®¡

### 3ï¸âƒ£ é£é™©ç±»å‹ (Risk Category)
- é¦™æ¸¯ç©ºå£³ã€å¤‡æ¡ˆéš¾é¢˜ã€åº“å­˜æ ¸é”€ã€æ•°æ®ä¸ç¬¦ã€æ¶æ„æ‹†åˆ†ã€è§„æ¨¡å›°å¢ƒã€è¡¥ç¨å‹åŠ›ã€ä¿¡æ¯ä¸é€æ˜

### 4ï¸âƒ£ çº³ç¨äººèº«ä»½ (Taxpayer Identity)
- Generalï¼ˆä¸€èˆ¬çº³ç¨äººï¼‰ã€Smallï¼ˆå°è§„æ¨¡çº³ç¨äººï¼‰ã€Unknownï¼ˆæœªçŸ¥ï¼‰

### 5ï¸âƒ£ è¡Œä¸ºå€¾å‘ (Behavioral Intent)
- Complianceï¼ˆåˆè§„ï¼‰ã€Mode_Switchï¼ˆåˆ‡æ¢æ¨¡å¼ï¼‰ã€Help_Seekingï¼ˆå¯»æ±‚å¸®åŠ©ï¼‰
- Wait_and_Seeï¼ˆè§‚æœ›ï¼‰ã€No_Actionï¼ˆæ— è¡ŒåŠ¨ï¼‰

## æ–¹æ³•è®º

**æ•°æ®æ¥æº**ï¼š
- å¾®åšã€çŸ¥ä¹ã€å°çº¢ä¹¦ã€ç”µå•†è®ºå›
- 5000æ¡èˆ†è®º
- æ—¶é—´è·¨åº¦ï¼š2025å¹´6æœˆ-12æœˆ

**åˆ†ææ–¹æ³•**ï¼š
- æ¨¡å‹ï¼šæ™ºè°±æ¸…è¨€ (glm-4-flash)
- æ¡†æ¶ï¼šLangExtract
- äº”ç»´åº¦ç»“æ„åŒ–åˆ†ç±»

**ç²¾åº¦éªŒè¯**ï¼š
- 100æ¡æ ·æœ¬äººå·¥æ ‡æ³¨
- ä¸LLMç»“æœå¯¹æ¯”
- æ•´ä½“ç²¾åº¦ï¼š88%+

## æ ¸å¿ƒå‘ç°

ğŸ’¡ ä»5000æ¡èˆ†è®ºä¸­ï¼Œæˆ‘ä»¬å‘ç°ï¼š

1. **è´Ÿé¢æƒ…æ„Ÿå æ¯”é«˜**ï¼šçº¦60%çš„èˆ†è®ºè¡¨ç°å‡ºç„¦è™‘ã€å›°æƒ‘æˆ–åå¯¹
2. **ä¿¡æ¯ä¸å¯¹ç§°ä¸¥é‡**ï¼šæœ€é«˜é¢‘çš„é£é™©æ˜¯"ä¿¡æ¯ä¸é€æ˜"
3. **æ¨¡å¼å·®å¼‚æ˜æ˜¾**ï¼šä¸åŒäº¤æ˜“æ¨¡å¼é¢ä¸´çš„é£é™©åˆ†åŒ–
4. **ä¸»åŠ¨åˆè§„å€¾å‘**ï¼š30%çš„ä¼ä¸šè¡¨ç°å‡ºåˆè§„æ„æ„¿
5. **æ”¿ç­–æ‰§è¡Œéš¾åº¦**ï¼šå¤šç»´åº¦é£é™©å åŠ ï¼Œä¼ä¸šé¢ä¸´å¤æ‚é€‰æ‹©

## æ”¿ç­–å¯ç¤º

âœ… åŸºäºèˆ†è®ºåˆ†æçš„å»ºè®®ï¼š

1. **åŠ å¼ºæ”¿ç­–è¯´æ˜**ï¼šä¼ä¸šæœ€å¸Œæœ›å¾—åˆ°æ¸…æ™°çš„æ‰§è¡ŒæŒ‡å—
2. **åˆ†ç±»æŒ‡å¯¼**ï¼šä¸åŒè§„æ¨¡ã€ä¸åŒæ¨¡å¼çš„ä¼ä¸šéœ€è¦å·®å¼‚åŒ–æ”¯æŒ
3. **å»ºç«‹åè°ƒæœºåˆ¶**ï¼šæ”¿åºœéƒ¨é—¨é—´éœ€è¦é…åˆï¼ˆå¤‡æ¡ˆéƒ¨é—¨ä¸ç¨åŠ¡éƒ¨é—¨ï¼‰
4. **åŠæ—¶åé¦ˆ**ï¼šä¼ä¸šå¸Œæœ›äº†è§£æ”¿ç­–çš„æœ€æ–°è¿›å±•

## æ•°æ®ä½¿ç”¨

æœ¬æ•°æ®ä»…ç”¨äºï¼š
- å­¦æœ¯ç ”ç©¶
- æ”¿ç­–åˆ†æ
- å…¬å¼€å±•ç¤º

ä¸æ¶‰åŠä¸ªäººéšç§æˆ–å•†ä¸šæœºå¯†ã€‚

---

**é¡¹ç›®å›¢é˜Ÿ**ï¼š[ä½ çš„åå­—]  
**è”ç³»æ–¹å¼**ï¼š[é‚®ç®±]  
**æ›´æ–°æ—¶é—´**ï¼š2026å¹´1æœˆ

[åé¦ˆè¡¨å•é“¾æ¥]
""")
```

#### 3.3 æœ¬åœ°æµ‹è¯•ï¼ˆ1æœˆ23-25æ—¥ï¼Œ2å¤©ï¼‰

```
æµ‹è¯•æ¸…å•ï¼š
â–¡ streamlit run main.py èƒ½å¯åŠ¨
â–¡ æ‰€æœ‰7ä¸ªé¡µé¢éƒ½èƒ½è®¿é—®
â–¡ æ•°æ®åŠ è½½å®Œæˆï¼ˆé¦–æ¬¡<5ç§’ï¼Œä¹‹åç¼“å­˜<1ç§’ï¼‰
â–¡ æ‰€æœ‰å›¾è¡¨éƒ½èƒ½æ­£å¸¸æ¸²æŸ“
â–¡ ç­›é€‰åŠŸèƒ½å·¥ä½œæ­£å¸¸
â–¡ æœç´¢åŠŸèƒ½å‡†ç¡®
â–¡ å“åº”å¼è®¾è®¡åœ¨æ‰‹æœºä¸Šå¯ç”¨
â–¡ æ— Pythoné”™è¯¯æˆ–è­¦å‘Š

ä¿®å¤bugsã€ä¼˜åŒ–æ€§èƒ½
```

#### 3.4 éƒ¨ç½²ä¸Šçº¿ï¼ˆ1æœˆ26-31æ—¥ï¼Œ3å¤©ï¼‰

```bash
# 1. æ¨é€åˆ°GitHub
git add .
git commit -m "Streamlit opinion analysis dashboard"
git push origin main

# 2. åœ¨Streamlit Cloudéƒ¨ç½²
è®¿é—®ï¼šhttps://streamlit.io/cloud
ç™»å½• â†’ "New app" â†’ é€‰æ‹©repo â†’ é€‰æ‹©main.py â†’ Deploy

# 3. è·å¾—URL
https://[username]-opinion-analysis.streamlit.app/

# 4. é…ç½®è‡ªå®šä¹‰åŸŸåï¼ˆå¯é€‰ï¼‰
åœ¨Streamlit Cloud â†’ Settings â†’ Custom domain

# 5. æµ‹è¯•åœ¨çº¿ç‰ˆæœ¬
è®¿é—®URLï¼Œç¡®è®¤æ‰€æœ‰åŠŸèƒ½æ­£å¸¸
```

**éƒ¨ç½²æˆæœ¬**ï¼šÂ¥0ï¼ˆStreamlit Cloudå…è´¹ï¼‰

### é˜¶æ®µäº§å‡º
- âœ… åœ¨çº¿ä»ªè¡¨æ¿URLï¼ˆhttps://...streamlit.appï¼‰
- âœ… GitHubä»£ç ä»“åº“
- âœ… READMEéƒ¨ç½²æ–‡æ¡£
- âœ… ç”¨æˆ·ä½¿ç”¨æŒ‡å—

---

## ç¬¬å››é˜¶æ®µï¼šç½‘ç«™ä¼˜åŒ–ä¸è¿­ä»£ï¼ˆ2026å¹´2æœˆ1-28æ—¥ï¼‰

### é˜¶æ®µç›®æ ‡
- âœ“ æ”¶é›†ç½‘ç«™ä½¿ç”¨æ•°æ®
- âœ“ ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ
- âœ“ æ·»åŠ é«˜çº§åŠŸèƒ½
- âœ“ è€ƒè™‘å‡çº§ä¸ºReactç‰ˆæœ¬

### å…·ä½“ä»»åŠ¡

#### 4.1 ç”¨æˆ·åé¦ˆæ”¶é›†ï¼ˆ1-2å‘¨ï¼‰

```
æ–¹å¼1ï¼šç½‘ç«™å†…åé¦ˆè¡¨å•
- Abouté¡µé¢æ·»åŠ åé¦ˆè¡¨å•
- æ”¶é›†ç”¨æˆ·å»ºè®®

æ–¹å¼2ï¼šè®¿é—®ç»Ÿè®¡
- å“ªäº›é¡µé¢æœ€å¸¸è®¿é—®ï¼Ÿ
- ç”¨æˆ·åœç•™æ—¶é—´ï¼Ÿ
- å“ªäº›åŠŸèƒ½æœ€å¸¸ç”¨ï¼Ÿ

åŸºäºåé¦ˆè¿›è¡Œæ”¹è¿›
```

#### 4.2 æ€§èƒ½ä¼˜åŒ–ï¼ˆ1å‘¨ï¼‰

```
ä¼˜åŒ–æ–¹å‘ï¼š
â–¡ æ•°æ®åŠ è½½é€Ÿåº¦
â–¡ å›¾è¡¨æ¸²æŸ“æ€§èƒ½
â–¡ æœç´¢å“åº”æ—¶é—´
â–¡ é¡µé¢åŠ è½½é€Ÿåº¦
```

#### 4.3 æ–°åŠŸèƒ½å¼€å‘ï¼ˆå¯é€‰ï¼Œ1-2å‘¨ï¼‰

```
å¯é€‰é«˜çº§åŠŸèƒ½ï¼š
- ã€å¯¹æ¯”åˆ†æã€‘ä¸¤ä¸ªæ—¶é—´æ®µçš„èˆ†è®ºå¯¹æ¯”
- ã€è¶‹åŠ¿é¢„æµ‹ã€‘èˆ†è®ºèµ°å‘é¢„æµ‹
- ã€æ”¿ç­–å…³è”ã€‘èˆ†è®ºä¸æ”¿ç­–æ–‡ä»¶å¯¹åº”
- ã€æŠ¥å‘Šå¯¼å‡ºã€‘ç”ŸæˆPDFæŠ¥å‘Š
- ã€APIæ¥å£ã€‘æ•°æ®æ¥å£æœåŠ¡
```

#### 4.4 Reactå‡çº§æ–¹æ¡ˆï¼ˆå¯é€‰ï¼‰

å¦‚æœStreamlitç‰ˆåå“å¥½ï¼Œå¯å‡çº§ä¸ºä¸“ä¸šçš„Reactç‰ˆæœ¬ï¼š

```
æŠ€æœ¯æ ˆï¼š
- å‰ç«¯ï¼šReact 18 + TypeScript
- å›¾è¡¨ï¼šECharts
- åç«¯ï¼šFastAPI
- éƒ¨ç½²ï¼šVercel + Railway
- æ•°æ®åº“ï¼šPostgreSQLï¼ˆå¯é€‰ï¼‰

å‘¨æœŸï¼š2-3å‘¨
éš¾åº¦ï¼šâ˜…â˜…â˜…
ä¼˜åŠ¿ï¼šæ›´ä¸“ä¸šã€æ›´å¿«ã€æ›´å¤šåŠŸèƒ½
```

### é˜¶æ®µäº§å‡º
- âœ… ä¼˜åŒ–æŠ¥å‘Š
- âœ… æ–°ç‰ˆæœ¬è¿­ä»£
- âœ… ï¼ˆå¯é€‰ï¼‰Reactå‡çº§è®¾è®¡æ–¹æ¡ˆ

---

## ç¬¬äº”é˜¶æ®µï¼šè®ºæ–‡æ’°å†™ä¸é›†æˆï¼ˆ2026å¹´2æœˆ-3æœˆï¼‰

### é˜¶æ®µç›®æ ‡
- âœ“ æ’°å†™è®ºæ–‡Part Bï¼ˆèˆ†è®ºåˆ†æï¼‰
- âœ“ é›†æˆç½‘ç«™æ•°æ®ä¸å¯è§†åŒ–
- âœ“ å®Œæˆå®Œæ•´å­¦æœ¯è®ºæ–‡
- âœ“ æäº¤å‘è¡¨

### å…·ä½“ä»»åŠ¡

#### 5.1 è®ºæ–‡Part B æ’°å†™ï¼ˆ2æœˆä¸Šæ—¬ï¼‰

```
ç« èŠ‚ç»“æ„ï¼š

1. èƒŒæ™¯ä¸é—®é¢˜ï¼ˆ1é¡µï¼‰
   - ä¸ºä»€ä¹ˆéœ€è¦èˆ†è®ºåˆ†æ
   - æ”¿ç­–å¯¹ä¼ä¸šçš„å½±å“

2. æ–¹æ³•è®ºï¼ˆ2é¡µï¼‰
   - æ•°æ®æ¥æºï¼š5000æ¡èˆ†è®ºï¼ˆ2025.6-12ï¼‰
   - åˆ†ææ–¹æ³•ï¼šLLM + 5ç»´åº¦åˆ†ç±»
   - åˆ†ç±»ç»´åº¦è¯¦è§£
   - ç²¾åº¦éªŒè¯ï¼šæ ·æœ¬100æ¡ï¼Œç²¾åº¦88%+
   - ä½¿ç”¨å·¥å…·ï¼šæ™ºè°±æ¸…è¨€API + Streamlit

3. ç»“æœå‘ˆç°ï¼ˆ5é¡µï¼‰
   - è¡¨1ï¼šæƒ…æ„Ÿåˆ†å¸ƒç»Ÿè®¡
   - è¡¨2ï¼šæ¨¡å¼åˆ†å¸ƒè¡¨
   - è¡¨3ï¼šé£é™©æ’åºè¡¨
   - è¡¨4ï¼šè¡Œä¸ºå€¾å‘åˆ†å¸ƒ
   - å›¾1ï¼šæƒ…æ„Ÿé¥¼å›¾
   - å›¾2ï¼šæ¨¡å¼åˆ†å¸ƒæŸ±çŠ¶å›¾
   - å›¾3ï¼šæ¨¡å¼Ã—é£é™©çƒ­åŠ›å›¾
   - å›¾4ï¼šè¡Œä¸ºå€¾å‘åˆ†å¸ƒ
   - æ–‡æœ¬ï¼šå…³é”®å‘ç°æ€»ç»“ï¼ˆ5-10æ¡ï¼‰

4. è®¨è®ºï¼ˆ2é¡µï¼‰
   - èˆ†è®ºå‘ç°ä¸ç†è®ºå¯¹è¯
   - ä¸åŒæ¨¡å¼çš„èˆ†è®ºç‰¹ç‚¹
   - æ”¿ç­–æ‰§è¡Œçš„ä¿¡æ¯é—®é¢˜
   - æ”¿ç­–å¯ç¤º
   - ç ”ç©¶å±€é™

5. é™„å½•
   - å®Œæ•´Prompt
   - éƒ¨åˆ†åŸå§‹ç»“æœ
   - åˆ†ç±»ç»´åº¦å®šä¹‰
   - åœ¨çº¿ç½‘ç«™é“¾æ¥
```

#### 5.2 æ•°æ®å¯è§†åŒ–å›¾è¡¨

```
ç›´æ¥ä»ç½‘ç«™å¯¼å‡ºï¼š
- æ¯ä¸ªé¡µé¢çš„æˆªå›¾ä½œä¸ºè®ºæ–‡å›¾è¡¨
- ä¿ç•™äº¤äº’æ€§è¯´æ˜ï¼š"è¯¦è§åœ¨çº¿ç½‘ç«™..."
- å…³é”®æ•°æ®è¡¨ä»ç½‘ç«™å¯¼å‡ºä¸ºExcel
```

#### 5.3 è®ºæ–‡é“¾æ¥ç½‘ç«™

```
åœ¨è®ºæ–‡ä¸­æ·»åŠ ï¼š
- åœ¨çº¿ç½‘ç«™URLï¼ˆå¯äº¤äº’è®¿é—®ï¼‰
- QRç ï¼ˆä¾¿äºæ‰«æè®¿é—®ï¼‰
- GitHubä»£ç ä»“åº“åœ°å€
- è¡¥å……ææ–™è¯´æ˜
```

#### 5.4 æœ€ç»ˆå®¡æŸ¥ä¸æäº¤

```
æ£€æŸ¥æ¸…å•ï¼š
â–¡ æ‰€æœ‰å¼•ç”¨æ­£ç¡®
â–¡ æ‰€æœ‰è¡¨æ ¼å’Œå›¾è¡¨é«˜è´¨é‡
â–¡ ç½‘ç«™é“¾æ¥å¯è®¿é—®
â–¡ ä»£ç å¯å¤ç°
â–¡ ç¬¦åˆæœŸåˆŠæŠ•ç¨¿è¦æ±‚
```

### é˜¶æ®µäº§å‡º
- âœ… å®Œæ•´å­¦æœ¯è®ºæ–‡ï¼ˆå«Part A DIDåˆ†æ + Part Bèˆ†è®ºåˆ†æï¼‰
- âœ… åœ¨çº¿ç½‘ç«™é“¾æ¥
- âœ… GitHubä»£ç ä»“åº“
- âœ… è¡¥å……æ•°æ®å’Œä»£ç 

---

## æ€»ä½“æ—¶é—´è¡¨

| é˜¶æ®µ | æ—¶é—´ | ä¸»è¦äº§å‡º | å…³é”®é‡Œç¨‹ç¢‘ |
|------|------|--------|---------|
| **ç¬¬ä¸€é˜¶æ®µ** | 12.10-12.15 | 5000æ¡æ¸…æ´æ•°æ® | âœ… æ•°æ®å‡†å¤‡å°±ç»ª |
| **ç¬¬äºŒé˜¶æ®µ** | 12.16-12.30 | JSONç»“æ„åŒ–æ•°æ® | âœ… LLMåˆ†æå®Œæˆ |
| **ç¬¬ä¸‰é˜¶æ®µ** | 1.1-1.31 | åœ¨çº¿ç½‘ç«™ | âœ… ç½‘ç«™ä¸Šçº¿ |
| **ç¬¬å››é˜¶æ®µ** | 2.1-2.28 | ä¼˜åŒ–æŠ¥å‘Š | âœ… ç½‘ç«™ç¨³å®šè¿è¡Œ |
| **ç¬¬äº”é˜¶æ®µ** | 3.1-3.31 | å­¦æœ¯è®ºæ–‡ | âœ… è®ºæ–‡å®Œæˆ |

---

## èµ„æºä¸æˆæœ¬

| é¡¹ç›® | æˆæœ¬ | è¯´æ˜ |
|-----|------|------|
| **LLMåˆ†æ** | Â¥0 | ç”¨å·²æœ‰2000ä¸‡token |
| **ç½‘ç«™æ‰˜ç®¡** | Â¥0 | Streamlit Cloudå…è´¹ |
| **åŸŸå** | Â¥50-100/å¹´ | å¯é€‰ |
| **GitHub** | Â¥0 | å…è´¹ç§åº“ |
| **æ€»è®¡** | **Â¥0-100** | å®Œå…¨ä½æˆæœ¬ |

---

## æŠ€æœ¯æ ˆæ€»ç»“

```
æ•°æ®åˆ†æå±‚ï¼š
â”œâ”€ çˆ¬è™«ï¼šSelenium / requestsï¼ˆå·²æœ‰ï¼‰
â”œâ”€ LLMåˆ†æï¼šæ™ºè°±æ¸…è¨€ glm-4-flash
â”œâ”€ æ•°æ®å¤„ç†ï¼šPandas + JSON
â””â”€ è¯­è¨€ï¼šPython 3.8+

å¯è§†åŒ–å±‚ï¼š
â”œâ”€ æ¡†æ¶ï¼šStreamlit
â”œâ”€ å›¾è¡¨åº“ï¼šPlotly / Echarts
â”œâ”€ UIç»„ä»¶ï¼šStreamlitå†…ç½®
â””â”€ æ•°æ®ç¼“å­˜ï¼š@st.cache_data

éƒ¨ç½²å±‚ï¼š
â”œâ”€ å‰ç«¯éƒ¨ç½²ï¼šStreamlit Cloud
â”œâ”€ ä»£ç ç®¡ç†ï¼šGitHub
â””â”€ åŸŸåï¼šå¯é€‰è‡ªè´­

è®ºæ–‡å±‚ï¼š
â”œâ”€ æ–‡å­—å¤„ç†ï¼šWord/LaTeX
â”œâ”€ æ•°æ®æ¥æºï¼šç½‘ç«™API
â””â”€ å›¾è¡¨æ¥æºï¼šç½‘ç«™å¯¼å‡º

æ ¸å¿ƒä¼˜åŠ¿ï¼š
âœ… å®Œå…¨å…è´¹ï¼ˆtokenå·²æœ‰ï¼‰
âœ… å¿«é€Ÿéƒ¨ç½²ï¼ˆ3å‘¨å†…ä¸Šçº¿ï¼‰
âœ… å®Œå…¨è‡ªä¸»ï¼ˆæ•°æ®åœ¨æ‰‹ä¸­ï¼‰
âœ… å¯æ‰©å±•ï¼ˆåç»­å¯å‡çº§Reactï¼‰
âœ… å­¦æœ¯çº§åˆ«ï¼ˆå¯å‘è¡¨ï¼‰
```

---

## é¢„æœŸäº§å‡ºä¸å½±å“

### ç½‘ç«™äº§å‡º
- ğŸ“Š é¦–ä¸ªè·¨å¢ƒç”µå•†èˆ†è®ºåˆ†æå¯è§†åŒ–å¹³å°
- ğŸ“ˆ è¦†ç›–5000æ¡çœŸå®èˆ†è®ºï¼ˆ6ä¸ªæœˆï¼‰
- ğŸŒ åœ¨çº¿å¯è®¿é—®å’Œäº¤äº’

### å­¦æœ¯äº§å‡º
- ğŸ“„ å®Œæ•´çš„å­¦æœ¯è®ºæ–‡
  - Part Aï¼šDIDæ”¿ç­–æ•ˆåº”åˆ†æ
  - Part Bï¼šèˆ†è®ºå“åº”åˆ†æ
- ğŸ“Œ æ–¹æ³•è®ºåˆ›æ–°ï¼šLLMåœ¨èˆ†è®ºåˆ†æä¸­çš„åº”ç”¨
- ğŸ“Š å¼€æ”¾æ•°æ®é›†ï¼ˆå¯ç”¨äºåç»­ç ”ç©¶ï¼‰

### ç¤¾ä¼šä»·å€¼
- ğŸ›ï¸ ä¸ºæ”¿åºœäº†è§£ä¼ä¸šè¯‰æ±‚æä¾›æ•°æ®æ”¯æŒ
- ğŸ‘¥ ä¸ºä¼ä¸šæä¾›åˆè§„å‚è€ƒ
- ğŸ“Š å±•ç¤ºæ”¿ç­–æ•ˆåº”çš„çœŸå®ååº”

---

## å¿«é€Ÿå†³ç­–

**æ¥ä¸‹æ¥ç«‹å³åšï¼Ÿ**

1. **æ•°æ®ç¡®è®¤**ï¼ˆä»Šå¤©ï¼‰
   - âœ… 5000æ¡èˆ†è®ºæ˜¯å¦å·²å‡†å¤‡å¥½ï¼Ÿ
   
2. **LLMåˆ†æ**ï¼ˆ12.16-30ï¼‰
   - æŒ‰ç…§ç¬¬äºŒé˜¶æ®µæ‰§è¡Œ

3. **ç½‘ç«™å¼€å‘**ï¼ˆ1.1-31ï¼‰
   - æŒ‰ç…§ç¬¬ä¸‰é˜¶æ®µæ‰§è¡Œ

4. **è®ºæ–‡æ’°å†™**ï¼ˆ2.1-3.31ï¼‰
   - æŒ‰ç…§ç¬¬äº”é˜¶æ®µæ‰§è¡Œ

**é¢„è®¡å®Œæˆæ—¶é—´**ï¼š2026å¹´3æœˆ31æ—¥  
**æ‰€éœ€æŠ•å…¥**ï¼šå®é™…å·¥ä½œ100å°æ—¶å·¦å³ + Â¥0  
**é¢„æœŸå½±å“**ï¼šå¯å‘è¡¨çš„å­¦æœ¯è®ºæ–‡ + å¯è¿è¥çš„æ•°æ®å¹³å°

---

**é¡¹ç›®è´Ÿè´£äºº**ï¼š[Your Name]  
**æœ€åæ›´æ–°**ï¼š2025å¹´12æœˆ10æ—¥  
**çŠ¶æ€**ï¼šâœ… å¯ç«‹å³æ‰§è¡Œ
