"""
BERTopicä¸»é¢˜åˆ†æå·¥å…· - æ·±åº¦è¯é¢˜å»ºæ¨¡
"""

from __future__ import annotations
import streamlit as st
import pandas as pd
import numpy as np
from typing import Optional, List, Any
import warnings
warnings.filterwarnings('ignore')

try:
    from bertopic import BERTopic
    from sentence_transformers import SentenceTransformer
    BERTOPIC_AVAILABLE = True
except ImportError:
    BERTOPIC_AVAILABLE = False


@st.cache_resource
def get_bertopic_model() -> Optional[Any]:
    """è·å–ç¼“å­˜çš„BERTopicæ¨¡å‹ï¼ˆä»…åˆå§‹åŒ–ä¸€æ¬¡ï¼‰"""
    if not BERTOPIC_AVAILABLE:
        return None
    
    try:
        # ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„embeddingæ¨¡å‹
        embedding_model = SentenceTransformer('distiluse-base-multilingual-cased-v2')
        model = BERTopic(
            embedding_model=embedding_model,
            language="chinese",
            calculate_probabilities=True,
            verbose=False
        )
        return model
    except Exception as e:
        st.warning(f"BERTopicåˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def train_bertopic(texts: List[str], model: Optional[Any] = None) -> tuple:
    """
    è®­ç»ƒBERTopicæ¨¡å‹æå–éšè—ä¸»é¢˜
    
    è¿”å›: (topics, probabilities, model)
    """
    if not BERTOPIC_AVAILABLE:
        st.warning("BERTopicæœªå®‰è£…ï¼Œè·³è¿‡é«˜çº§ä¸»é¢˜åˆ†æ")
        return None, None, None
    
    if model is None:
        model = get_bertopic_model()
    
    if model is None:
        return None, None, None
    
    try:
        with st.spinner("ğŸ¤– æ­£åœ¨è®­ç»ƒBERTopicæ¨¡å‹ï¼Œæå–éšè—ä¸»é¢˜..."):
            topics, probs = model.fit_transform(texts)
        return topics, probs, model
    except Exception as e:
        st.warning(f"ä¸»é¢˜æå–å¤±è´¥: {e}")
        return None, None, None


def visualize_topics_2d(model: Optional[Any], topics: Optional[np.ndarray]) -> Optional[object]:
    """ç”Ÿæˆ2Dä¸»é¢˜å¯è§†åŒ–ï¼ˆäº¤äº’å¼å›¾è¡¨ï¼‰"""
    if model is None or topics is None:
        return None
    
    try:
        return model.visualize_topics()
    except Exception as e:
        st.warning(f"ä¸»é¢˜å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        return None


def visualize_topic_hierarchy(model: Optional[Any]) -> Optional[object]:
    """ç”Ÿæˆä¸»é¢˜å±‚çº§å…³ç³»å›¾"""
    if model is None:
        return None
    
    try:
        # å°è¯•ç”Ÿæˆå±‚çº§å…³ç³»
        if len(model.get_topic_info()) > 2:
            hierarchical_topics = model.hierarchical_topics(
                model.documents,
                linkage_function=lambda x: __import__('scipy').cluster.hierarchy.linkage(x, "ward")
            )
            return model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)
        else:
            st.info("ğŸ’¡ ä¸»é¢˜æ•°é‡å¤ªå°‘ï¼Œæ— æ³•ç”Ÿæˆå±‚çº§å…³ç³»å›¾")
            return None
    except Exception as e:
        st.warning(f"å±‚çº§å…³ç³»å›¾ç”Ÿæˆå¤±è´¥: {e}")
        return None


def visualize_topic_similarity(model: Optional[Any]) -> Optional[object]:
    """ç”Ÿæˆä¸»é¢˜ç›¸ä¼¼åº¦çƒ­åŠ›å›¾"""
    if model is None:
        return None
    
    try:
        return model.visualize_heatmap(n_clusters=5)
    except Exception as e:
        st.warning(f"ç›¸ä¼¼åº¦çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {e}")
        return None


def visualize_topic_terms(model: Optional[Any], top_n: int = 5) -> Optional[object]:
    """ç”Ÿæˆä¸»é¢˜è¯è¯­çš„é‡è¦æ€§å›¾è¡¨"""
    if model is None:
        return None
    
    try:
        return model.visualize_terms(top_n_terms=top_n)
    except Exception as e:
        st.warning(f"è¯è¯­é‡è¦æ€§å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        return None


def get_topic_keywords(model: Optional[Any], topic: int, top_n: int = 5) -> List[tuple]:
    """è·å–æŒ‡å®šä¸»é¢˜çš„å…³é”®è¯"""
    if model is None:
        return []
    
    try:
        topic_info = model.get_topic(topic)
        return topic_info[:top_n] if topic_info else []
    except Exception as e:
        return []


def get_topics_summary(model: Optional[Any]) -> pd.DataFrame:
    """è·å–æ‰€æœ‰ä¸»é¢˜çš„æ‘˜è¦ä¿¡æ¯"""
    if model is None:
        return pd.DataFrame()
    
    try:
        topic_info = model.get_topic_info()
        return topic_info[['Topic', 'Count', 'Name']].copy()
    except Exception as e:
        return pd.DataFrame()


def get_documents_by_topic(df: pd.DataFrame, topics: np.ndarray, topic_id: int, top_n: int = 5) -> pd.DataFrame:
    """è·å–æŒ‡å®šä¸»é¢˜ä¸‹çš„æ–‡æ¡£åˆ—è¡¨"""
    if topics is None:
        return pd.DataFrame()
    
    try:
        mask = topics == topic_id
        topic_docs = df[mask].head(top_n)[['source_text', 'sentiment', 'risk_level']].copy()
        return topic_docs
    except Exception as e:
        return pd.DataFrame()


def visualize_documents_2d(model: Optional[Any], docs: List[str], topics: np.ndarray) -> Optional[object]:
    """ç”Ÿæˆæ–‡æ¡£åœ¨2Dç©ºé—´çš„åˆ†å¸ƒï¼ˆUmapé™ç»´ï¼‰"""
    if model is None or topics is None:
        return None
    
    try:
        return model.visualize_documents(docs, topics=topics, hide_document_hover=False)
    except Exception as e:
        try:
            # å¦‚æœæœ‰embeddingå°±ç”¨ï¼Œæ²¡æœ‰å°±ç®€åŒ–ç‰ˆæœ¬
            return model.visualize_documents(docs, hide_document_hover=True)
        except:
            return None


def visualize_term_distribution(model: Optional[Any], top_n_topics: int = 5) -> Optional[object]:
    """ç”Ÿæˆå„ä¸»é¢˜çš„è¯é¢‘åˆ†å¸ƒ"""
    if model is None:
        return None
    
    try:
        return model.visualize_barchart(top_n_topics=top_n_topics)
    except Exception as e:
        return None


def generate_topic_tree(model: Optional[Any], df: pd.DataFrame, topics: np.ndarray) -> str:
    """ç”Ÿæˆä¸»é¢˜çš„æ ‘å½¢ç»“æ„æ–‡æœ¬"""
    if model is None or topics is None:
        return ""
    
    try:
        topic_info = model.get_topic_info()
        tree_text = ""
        
        for idx, row in topic_info[topic_info['Topic'] != -1].iterrows():
            topic_id = row['Topic']
            topic_name = row['Name']
            count = row['Count']
            
            # è·å–è¯¥ä¸»é¢˜çš„å‰3ä¸ªæ–‡æ¡£
            mask = topics == topic_id
            docs = df[mask].head(3)
            
            tree_text += f"**è¯é¢˜{int(topic_id)}: {topic_name}** ({count} æ¡æ–‡æ¡£)\n"
            
            for i, (_, doc) in enumerate(docs.iterrows(), 1):
                text_preview = doc['source_text'][:60] + "..." if len(doc['source_text']) > 60 else doc['source_text']
                tree_text += f"  â”œâ”€ {i}. \"{text_preview}\"\n"
                tree_text += f"     æƒ…æ„Ÿ: {doc['sentiment']} | é£é™©: {doc['risk_level']}\n"
            
            tree_text += "\n"
        
        return tree_text
    except Exception as e:
        return f"ç”Ÿæˆå¤±è´¥: {e}"


def visualize_term_score_decline(model: Optional[Any], top_n_topics: int = 5) -> Optional[object]:
    """ç”Ÿæˆc-TF-IDFåˆ†æ•°è¡°å‡å›¾ï¼ˆæ˜¾ç¤ºè¯æ±‡æƒé‡çš„é€’å‡ï¼‰"""
    if model is None:
        return None
    
    try:
        return model.visualize_term_rank(top_n_topics=top_n_topics, log_scale=False)
    except Exception as e:
        return None


def get_hierarchical_topics(model: Optional[Any]) -> Optional[pd.DataFrame]:
    """è®¡ç®—å¹¶è¿”å›å±‚çº§ä¸»é¢˜ç»“æ„"""
    if model is None:
        return None
    
    try:
        # éœ€è¦æœ‰è¶³å¤Ÿçš„ä¸»é¢˜æ‰èƒ½ç”Ÿæˆå±‚çº§
        if len(model.get_topic_info()) > 2:
            hierarchical_topics = model.hierarchical_topics(
                model.documents,
                linkage_function=lambda x: __import__('scipy').cluster.hierarchy.linkage(x, "ward")
            )
            return hierarchical_topics
        else:
            return None
    except Exception as e:
        return None


def visualize_hierarchical_documents(model: Optional[Any], texts: List[str], topics: np.ndarray) -> Optional[object]:
    """ç”Ÿæˆåˆ†å±‚æ–‡æ¡£å¯è§†åŒ–ï¼ˆåœ¨å±‚çº§æ ‘çš„2Dç©ºé—´ä¸­ï¼‰"""
    if model is None or topics is None or len(texts) == 0:
        return None
    
    try:
        # è·å–åˆ†å±‚ä¸»é¢˜
        if len(model.get_topic_info()) > 2:
            hierarchical_topics = model.hierarchical_topics(
                model.documents,
                linkage_function=lambda x: __import__('scipy').cluster.hierarchy.linkage(x, "ward")
            )
            # å°è¯•å¯è§†åŒ–åˆ†å±‚æ–‡æ¡£
            return model.visualize_hierarchical_documents(texts, hierarchical_topics=hierarchical_topics, hide_document_hover=True)
        else:
            return None
    except Exception as e:
        return None


def get_topic_keywords_detailed(model: Optional[Any], topic_id: int, top_n: int = 10) -> pd.DataFrame:
    """è·å–æŒ‡å®šä¸»é¢˜çš„å…³é”®è¯åŠå…¶c-TF-IDFåˆ†æ•°"""
    if model is None:
        return pd.DataFrame()
    
    try:
        topic_info = model.get_topic(topic_id)
        if topic_info:
            # topic_info æ˜¯ [(word, score), ...] çš„åˆ—è¡¨
            keywords_df = pd.DataFrame(topic_info[:top_n], columns=['å…³é”®è¯', 'c-TF-IDFåˆ†æ•°'])
            keywords_df['æ’å'] = range(1, len(keywords_df) + 1)
            return keywords_df[['æ’å', 'å…³é”®è¯', 'c-TF-IDFåˆ†æ•°']]
        return pd.DataFrame()
    except Exception as e:
        return pd.DataFrame()


def get_topic_text_representation(model: Optional[Any], topic_id: int) -> str:
    """è·å–ä¸»é¢˜çš„æ–‡æœ¬è¡¨ç¤ºï¼ˆç”±ç”Ÿæˆæ¨¡å‹ç”Ÿæˆï¼‰"""
    if model is None:
        return ""
    
    try:
        # è·å–ä¸»é¢˜çš„æ ‡ç­¾ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        topic_info = model.get_topic_info()
        if topic_info is not None and len(topic_info) > 0:
            topic_row = topic_info[topic_info['Topic'] == topic_id]
            if not topic_row.empty:
                return topic_row.iloc[0]['Name']
        return f"è¯é¢˜{topic_id}"
    except Exception as e:
        return f"è¯é¢˜{topic_id}"


def calculate_topic_distribution(model: Optional[Any], texts: List[str]) -> Optional[np.ndarray]:
    """è®¡ç®—æ–‡æ¡£çš„ä¸»é¢˜åˆ†å¸ƒæ¦‚ç‡çŸ©é˜µ"""
    if model is None or len(texts) == 0:
        return None
    
    try:
        # å¦‚æœä½¿ç”¨äº†calculate_probabilities=Trueï¼Œå¯ä»¥ç›´æ¥è·å–
        if hasattr(model, 'probabilities_') and model.probabilities_ is not None:
            return model.probabilities_
        else:
            # å¦åˆ™å°è¯•ä¼°è®¡ä¸»é¢˜åˆ†å¸ƒ
            return model.approximate_distribution(texts)
    except Exception as e:
        return None


def visualize_topic_per_class(model: Optional[Any], df: pd.DataFrame, class_column: str = 'sentiment') -> Optional[object]:
    """æŒ‰åˆ†ç±»ï¼ˆå¦‚æƒ…æ„Ÿç±»åˆ«ï¼‰ç”Ÿæˆä¸»é¢˜åˆ†å¸ƒå¯è§†åŒ–"""
    if model is None or df is None or class_column not in df.columns:
        return None
    
    try:
        # è·å–æ‰€æœ‰å”¯ä¸€çš„ç±»åˆ«
        classes = df[class_column].unique()
        
        # åˆ›å»ºç®€å•çš„æŸ±çŠ¶å›¾å¯¹æ¯”
        import plotly.graph_objects as go
        
        fig = go.Figure()
        topic_info = model.get_topic_info()
        
        for class_val in classes:
            class_mask = df[class_column] == class_val
            topic_counts = []
            
            for topic_id in topic_info['Topic']:
                if topic_id == -1:  # è·³è¿‡å™ªå£°
                    continue
                count = len(df[class_mask & (df.index.isin([i for i, t in enumerate(model.topics_) if t == topic_id]))])
                topic_counts.append(count)
            
            fig.add_trace(go.Bar(
                name=str(class_val),
                x=topic_info[topic_info['Topic'] != -1]['Topic'].astype(str),
                y=topic_counts,
                text=topic_counts,
                textposition='auto',
            ))
        
        fig.update_layout(
            title="æŒ‰åˆ†ç±»ç»Ÿè®¡çš„ä¸»é¢˜åˆ†å¸ƒ",
            xaxis_title="ä¸»é¢˜ID",
            yaxis_title="æ–‡æ¡£æ•°é‡",
            barmode='group',
            height=400,
            hovermode='x unified'
        )
        
        return fig
    except Exception as e:
        return None
