"""
BERTopicä¸»é¢˜åˆ†æå·¥å…· - æ·±åº¦è¯é¢˜å»ºæ¨¡
"""

from __future__ import annotations
import streamlit as st
import pandas as pd
import numpy as np
from typing import Optional, List, Any
import warnings
warnings.filterwarnings('ignore')

try:
    from bertopic import BERTopic
    from sentence_transformers import SentenceTransformer
    BERTOPIC_AVAILABLE = True
except ImportError:
    BERTOPIC_AVAILABLE = False


@st.cache_resource
def get_bertopic_model() -> Optional[Any]:
    """è·å–ç¼“å­˜çš„BERTopicæ¨¡å‹ï¼ˆä»…åˆå§‹åŒ–ä¸€æ¬¡ï¼‰"""
    if not BERTOPIC_AVAILABLE:
        return None
    
    try:
        # ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„embeddingæ¨¡å‹
        embedding_model = SentenceTransformer('distiluse-base-multilingual-cased-v2')
        model = BERTopic(
            embedding_model=embedding_model,
            language="chinese",
            calculate_probabilities=True,
            verbose=False
        )
        return model
    except Exception as e:
        st.warning(f"BERTopicåˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def train_bertopic(texts: List[str], model: Optional[Any] = None) -> tuple:
    """
    è®­ç»ƒBERTopicæ¨¡å‹æå–éšè—ä¸»é¢˜
    
    è¿”å›: (topics, probabilities, model)
    """
    if not BERTOPIC_AVAILABLE:
        st.warning("BERTopicæœªå®‰è£…ï¼Œè·³è¿‡é«˜çº§ä¸»é¢˜åˆ†æ")
        return None, None, None
    
    if model is None:
        model = get_bertopic_model()
    
    if model is None:
        return None, None, None
    
    try:
        with st.spinner("ğŸ¤– æ­£åœ¨è®­ç»ƒBERTopicæ¨¡å‹ï¼Œæå–éšè—ä¸»é¢˜..."):
            topics, probs = model.fit_transform(texts)
        return topics, probs, model
    except Exception as e:
        st.warning(f"ä¸»é¢˜æå–å¤±è´¥: {e}")
        return None, None, None


def visualize_topics_2d(model: Optional[Any], topics: Optional[np.ndarray]) -> Optional[object]:
    """ç”Ÿæˆ2Dä¸»é¢˜å¯è§†åŒ–ï¼ˆäº¤äº’å¼å›¾è¡¨ï¼‰"""
    if model is None or topics is None:
        return None
    
    try:
        return model.visualize_topics()
    except Exception as e:
        st.warning(f"ä¸»é¢˜å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        return None


def visualize_topic_hierarchy(model: Optional[Any]) -> Optional[object]:
    """ç”Ÿæˆä¸»é¢˜å±‚çº§å…³ç³»å›¾"""
    if model is None:
        return None
    
    try:
        # å°è¯•ç”Ÿæˆå±‚çº§å…³ç³»
        if len(model.get_topic_info()) > 2:
            hierarchical_topics = model.hierarchical_topics(
                model.documents,
                linkage_function=lambda x: __import__('scipy').cluster.hierarchy.linkage(x, "ward")
            )
            return model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)
        else:
            st.info("ğŸ’¡ ä¸»é¢˜æ•°é‡å¤ªå°‘ï¼Œæ— æ³•ç”Ÿæˆå±‚çº§å…³ç³»å›¾")
            return None
    except Exception as e:
        st.warning(f"å±‚çº§å…³ç³»å›¾ç”Ÿæˆå¤±è´¥: {e}")
        return None


def visualize_topic_similarity(model: Optional[Any]) -> Optional[object]:
    """ç”Ÿæˆä¸»é¢˜ç›¸ä¼¼åº¦çƒ­åŠ›å›¾"""
    if model is None:
        return None
    
    try:
        return model.visualize_heatmap(n_clusters=5)
    except Exception as e:
        st.warning(f"ç›¸ä¼¼åº¦çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {e}")
        return None


def visualize_topic_terms(model: Optional[Any], top_n: int = 5) -> Optional[object]:
    """ç”Ÿæˆä¸»é¢˜è¯è¯­çš„é‡è¦æ€§å›¾è¡¨"""
    if model is None:
        return None
    
    try:
        return model.visualize_terms(top_n_terms=top_n)
    except Exception as e:
        st.warning(f"è¯è¯­é‡è¦æ€§å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        return None


def get_topic_keywords(model: Optional[Any], topic: int, top_n: int = 5) -> List[tuple]:
    """è·å–æŒ‡å®šä¸»é¢˜çš„å…³é”®è¯"""
    if model is None:
        return []
    
    try:
        topic_info = model.get_topic(topic)
        return topic_info[:top_n] if topic_info else []
    except Exception as e:
        return []


def get_topics_summary(model: Optional[Any]) -> pd.DataFrame:
    """è·å–æ‰€æœ‰ä¸»é¢˜çš„æ‘˜è¦ä¿¡æ¯"""
    if model is None:
        return pd.DataFrame()
    
    try:
        topic_info = model.get_topic_info()
        return topic_info[['Topic', 'Count', 'Name']].copy()
    except Exception as e:
        return pd.DataFrame()


def get_documents_by_topic(df: pd.DataFrame, topics: np.ndarray, topic_id: int, top_n: int = 5) -> pd.DataFrame:
    """è·å–æŒ‡å®šä¸»é¢˜ä¸‹çš„æ–‡æ¡£åˆ—è¡¨"""
    if topics is None:
        return pd.DataFrame()
    
    try:
        mask = topics == topic_id
        topic_docs = df[mask].head(top_n)[['source_text', 'sentiment', 'risk_level']].copy()
        return topic_docs
    except Exception as e:
        return pd.DataFrame()


def generate_topic_tree(model: Optional[Any], df: pd.DataFrame, topics: np.ndarray) -> str:
    """ç”Ÿæˆä¸»é¢˜çš„æ ‘å½¢ç»“æ„æ–‡æœ¬"""
    if model is None or topics is None:
        return ""
    
    try:
        topic_info = model.get_topic_info()
        tree_text = ""
        
        for idx, row in topic_info[topic_info['Topic'] != -1].iterrows():
            topic_id = row['Topic']
            topic_name = row['Name']
            count = row['Count']
            
            # è·å–è¯¥ä¸»é¢˜çš„å‰3ä¸ªæ–‡æ¡£
            mask = topics == topic_id
            docs = df[mask].head(3)
            
            tree_text += f"**è¯é¢˜{int(topic_id)}: {topic_name}** ({count} æ¡æ–‡æ¡£)\n"
            
            for i, (_, doc) in enumerate(docs.iterrows(), 1):
                text_preview = doc['source_text'][:60] + "..." if len(doc['source_text']) > 60 else doc['source_text']
                tree_text += f"  â”œâ”€ {i}. \"{text_preview}\"\n"
                tree_text += f"     æƒ…æ„Ÿ: {doc['sentiment']} | é£é™©: {doc['risk_level']}\n"
            
            tree_text += "\n"
        
        return tree_text
    except Exception as e:
        return f"ç”Ÿæˆå¤±è´¥: {e}"
