"""
äº’åŠ¨åˆ†æå·¥å…·é¡µé¢ - Phase 4 å¯è§£é‡Šæ€§åŠŸèƒ½
BERTopic F101-F103: å•æ–‡æ¡£åˆ†æã€Tokençº§åˆ†æã€ç¦»ç¾¤å€¼å¤„ç†
"""

import streamlit as st
import pandas as pd
import numpy as np
from utils.data_loader import (
    load_analysis_data,
    translate_sentiment,
    translate_risk,
    translate_topic
)
from utils.bertopic_analyzer import (
    train_bertopic,
    visualize_distribution,
    visualize_approximate_distribution,
    reduce_outliers,
    get_topics_summary,
    set_topic_labels,
    visualize_barchart_comparison,
    search_topics,
    BERTOPIC_AVAILABLE
)

st.set_page_config(page_title="äº’åŠ¨åˆ†æå·¥å…·", page_icon="ğŸ”®", layout="wide")

st.title("ğŸ”® äº’åŠ¨åˆ†æå·¥å…· (Phase 4)")
st.write("ä½¿ç”¨BERTopicçš„é«˜çº§äº¤äº’åŠŸèƒ½ï¼Œæ·±å…¥ç†è§£AIçš„å†³ç­–è¿‡ç¨‹")

if not BERTOPIC_AVAILABLE:
    st.error("âš ï¸ BERTopicæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨äº’åŠ¨åˆ†æå·¥å…·")
    st.stop()

def load_data():
    return load_analysis_data()

df = load_data()

# è®­ç»ƒæ¨¡å‹ï¼ˆç¼“å­˜ç»“æœä»¥åŠ é€Ÿï¼‰
with st.spinner("ğŸ¤– åˆå§‹åŒ–BERTopicæ¨¡å‹..."):
    texts = df['source_text'].tolist()
    topics, probs, model = train_bertopic(texts)

if model is None or topics is None:
    st.error("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
    st.stop()

st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼å‘ç°{len(np.unique(topics))-1}ä¸ªéšè—ä¸»é¢˜")

st.markdown("---")

# åˆ›å»º6ä¸ªTab
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“„ å•æ–‡æ¡£ä¸»é¢˜åˆ†æ",
    "ğŸ”¤ Tokençº§è¯åˆ†æ",
    "ğŸ§¹ ç¦»ç¾¤å€¼å¤„ç†",
    "ğŸ·ï¸ è‡ªå®šä¹‰æ ‡ç­¾",
    "ğŸ“Š è¯æƒé‡å¯¹æ¯”",
    "ğŸ” å…³é”®è¯æœç´¢"
])

# ============================================================================
# Tab 1: å•æ–‡æ¡£ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒ (F101)
# ============================================================================
with tab1:
    st.subheader("ğŸ“„ å•æ–‡æ¡£ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒåˆ†æ (F101)")
    st.write("é€‰æ‹©ä¸€æ¡æ„è§ï¼ŒæŸ¥çœ‹AIå¦‚ä½•åˆ†é…å„ä¸»é¢˜æ¦‚ç‡ï¼Œç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # æ–‡æ¡£é€‰æ‹©
        doc_selector = st.slider(
            "é€‰æ‹©æ–‡æ¡£",
            0, len(df) - 1, 0,
            help="æ»‘åŠ¨é€‰æ‹©è¦åˆ†æçš„æ–‡æ¡£ç´¢å¼•"
        )
    
    with col2:
        st.metric("å½“å‰æ–‡æ¡£", f"#{doc_selector}")
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ–‡æ¡£å†…å®¹
    selected_doc = df.iloc[doc_selector]
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.write("**åŸæ–‡å†…å®¹**:")
        st.markdown(f"> {selected_doc['source_text']}")
    
    with col2:
        st.write("**æ–‡æ¡£å±æ€§**:")
        st.write(f"æƒ…æ„Ÿ: {translate_sentiment(selected_doc['sentiment'])}")
        st.write(f"é£é™©: {translate_risk(selected_doc['risk_level'])}")
        st.write(f"è¯é¢˜: {translate_topic(selected_doc['topic'])}")
    
    st.markdown("---")
    
    # ç”Ÿæˆæ¦‚ç‡åˆ†å¸ƒå¯è§†åŒ–
    st.write("**ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒ**:")
    st.write("ä¸‹å›¾å±•ç¤ºè¯¥æ–‡æ¡£å±äºå„ä¸»é¢˜çš„ç½®ä¿¡åº¦ï¼ˆä»…æ˜¾ç¤º>1.5%çš„ä¸»é¢˜ï¼‰")
    
    min_prob = st.slider("æœ€å°æ¦‚ç‡é˜ˆå€¼", 0.0, 0.1, 0.015, 0.005, key="f101_prob")
    
    viz = visualize_distribution(model, doc_selector, min_probability=min_prob)
    if viz:
        st.plotly_chart(viz, use_container_width=True)
    else:
        st.warning("âš ï¸ æ— æ³•ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ¨¡å‹å¯èƒ½æœªå¯ç”¨calculate_probabilities=Trueï¼‰")
    
    st.markdown("---")
    
    st.info("""
    ğŸ’¡ **å¦‚ä½•ç†è§£è¿™ä¸ªå›¾**:
    - Xè½´: æ–‡æ¡£å¯èƒ½å±äºçš„å„ä¸ªä¸»é¢˜
    - Yè½´: æ¦‚ç‡ï¼ˆ0-1ï¼‰
    - æŸ±å­é«˜åº¦è¶Šé«˜ï¼Œè¯´æ˜æ¨¡å‹è¶Šç¡®ä¿¡è¯¥æ–‡æ¡£å±äºè¯¥ä¸»é¢˜
    - æ¦‚ç‡åˆ†æ•£ = æ–‡æ¡£æ¶‰åŠå¤šä¸ªä¸»é¢˜ï¼›æ¦‚ç‡é›†ä¸­ = æ–‡æ¡£ä¸»é¢˜æ˜ç¡®
    
    **å¯è§£é‡Šæ€§ä»·å€¼**:
    âœ“ ç†è§£æ¨¡å‹å¯¹å•æ¡æ„è§çš„åˆ¤æ–­ä¿¡å¿ƒ
    âœ“ è¯†åˆ«å¤šä¸»é¢˜æ–‡æ¡£ï¼ˆæ¦‚ç‡åˆ†æ•£çš„æƒ…å†µï¼‰
    âœ“ è°ƒè¯•æ¨¡å‹ç½®ä¿¡åº¦ï¼Œå‘ç°å¼‚å¸¸åˆ†ç±»
    """)

# ============================================================================
# Tab 2: Tokençº§ä¸»é¢˜åˆ†æ (F102)
# ============================================================================
with tab2:
    st.subheader("ğŸ”¤ Tokençº§è¯ä¸»é¢˜åˆ†æ (F102)")
    st.write("ç²¾ç¡®åˆ°å•è¯çº§åˆ«ï¼Œçœ‹å“ªäº›å…³é”®è¯è§¦å‘äº†å“ªä¸ªä¸»é¢˜")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        doc_selector2 = st.slider(
            "é€‰æ‹©æ–‡æ¡£è¿›è¡Œè¯çº§åˆ†æ",
            0, len(df) - 1, 0,
            help="é€‰æ‹©è¦åˆ†æçš„æ–‡æ¡£",
            key="f102_doc"
        )
    
    with col2:
        st.metric("å½“å‰æ–‡æ¡£", f"#{doc_selector2}")
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ–‡æ¡£å†…å®¹
    selected_doc2 = df.iloc[doc_selector2]
    
    st.write("**å¾…åˆ†ææ–‡æ¡£**:")
    st.markdown(f"> {selected_doc2['source_text']}")
    
    st.markdown("---")
    
    # ç”ŸæˆTokençº§åˆ†å¸ƒ
    st.write("**è¯çº§ä¸»é¢˜åˆ†å¸ƒ**:")
    st.write("ä»¥ä¸‹è¡¨æ ¼å±•ç¤ºæ¯ä¸ªè¯æœ€å¯èƒ½å±äºçš„ä¸»é¢˜åŠç½®ä¿¡åº¦")
    
    result = visualize_approximate_distribution(model, texts, doc_selector2, calculate_tokens=True)
    
    if result and isinstance(result, dict):
        # æ˜¾ç¤ºä¸»é¢˜çº§åˆ†å¸ƒ
        if 'ä¸»é¢˜åˆ†å¸ƒ' in result:
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.write("**ä¸»é¢˜çº§æ¦‚ç‡åˆ†å¸ƒ**:")
                st.dataframe(result['ä¸»é¢˜åˆ†å¸ƒ'], use_container_width=True)
            
            with col2:
                st.write("**è¯çº§åˆ†å¸ƒ**:")
                if 'è¯çº§åˆ†å¸ƒ' in result:
                    st.dataframe(result['è¯çº§åˆ†å¸ƒ'], use_container_width=True)
                else:
                    st.info("ğŸ’¡ è¯çº§åˆ†å¸ƒè®¡ç®—ä¸­...")
    else:
        st.warning("âš ï¸ æ— æ³•è®¡ç®—Tokençº§åˆ†å¸ƒï¼ˆå¯èƒ½éœ€è¦å¯ç”¨approximate_distributionï¼‰")
    
    st.markdown("---")
    
    st.info("""
    ğŸ’¡ **å¦‚ä½•ç†è§£Tokençº§åˆ†æ**:
    - æ¯ä¸ªè¯éƒ½ä¼šæ¿€æ´»æŸä¸ªä¸»é¢˜ï¼ˆç½®ä¿¡åº¦ï¼‰
    - é«˜ç½®ä¿¡åº¦çš„è¯æ˜¯è¯¥ä¸»é¢˜çš„"å…³é”®è§¦å‘è¯"
    - å¯ç”¨äºç†è§£ä¸ºä»€ä¹ˆè¯¥æ–‡æ¡£è¢«åˆ†åˆ°æŸä¸ªä¸»é¢˜
    
    **å¯è§£é‡Šæ€§ä»·å€¼**:
    âœ“ çœ‹æ¸…AIçš„"è§†è§’" - å“ªäº›è¯æœ€é‡è¦
    âœ“ è´¨é‡æ£€æµ‹ - å‘ç°é”™è¯¯åˆ†ç±»çš„åŸå› 
    âœ“ æ¨¡å‹æ”¹è¿› - è¯†åˆ«éœ€è¦è°ƒæ•´çš„è¯æ±‡æƒé‡
    """)

# ============================================================================
# Tab 3: ç¦»ç¾¤å€¼å¤„ç† (F103)
# ============================================================================
with tab3:
    st.subheader("ğŸ§¹ ç¦»ç¾¤å€¼è‡ªåŠ¨é‡åˆ†ç±» (F103)")
    st.write("å°†æ— æ³•æ¸…æ™°åˆ†ç±»çš„æ–‡æ¡£(Noise=-1)é‡æ–°åˆ†é…åˆ°åˆé€‚ä¸»é¢˜")
    
    st.markdown("---")
    
    # å½“å‰ç»Ÿè®¡
    col1, col2, col3 = st.columns(3)
    
    noise_count = np.sum(topics == -1)
    total_count = len(topics)
    noise_pct = noise_count / total_count * 100 if total_count > 0 else 0
    
    with col1:
        st.metric("å½“å‰ç¦»ç¾¤å€¼æ•°é‡", noise_count)
    
    with col2:
        st.metric("ç¦»ç¾¤å€¼å æ¯”", f"{noise_pct:.1f}%")
    
    with col3:
        st.metric("å¯åˆ†é…ä¸»é¢˜æ•°", len(np.unique(topics[topics != -1])))
    
    st.markdown("---")
    
    st.write("**é‡åˆ†ç±»é…ç½®**:")
    
    col1, col2 = st.columns(2)
    
    with col1:
        strategy = st.radio(
            "é€‰æ‹©é‡åˆ†ç±»ç­–ç•¥",
            [
                "probabilities - HDBSCANè½¯èšç±»æ¦‚ç‡ï¼ˆæœ€ç¨³å®šï¼‰",
                "distributions - è¿‘ä¼¼ä¸»é¢˜åˆ†å¸ƒï¼ˆè¾ƒå¿«ï¼‰",
                "c-tf-idf - è¯é¢‘ç›¸ä¼¼åº¦ï¼ˆæœ€å¿«ï¼‰",
                "embeddings - è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆæœ€å‡†ç¡®ä½†æœ€æ…¢ï¼‰"
            ],
            help="ä¸åŒç­–ç•¥çš„ç²¾åº¦å’Œé€Ÿåº¦æƒè¡¡",
            key="reduce_strategy"
        )
        # æå–ç­–ç•¥åç§°
        strategy_name = strategy.split(" - ")[0]
    
    with col2:
        threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            0.05, 0.5, 0.1, 0.05,
            help="åªé‡åˆ†é…ç½®ä¿¡åº¦>é˜ˆå€¼çš„ç¦»ç¾¤å€¼ï¼ˆè¶Šä½è¶Šæ¿€è¿›ï¼‰"
        )
    
    st.markdown("---")
    
    # æ‰§è¡Œé‡åˆ†ç±»
    if st.button("ğŸš€ æ‰§è¡Œé‡åˆ†ç±»", key="reduce_outliers_btn"):
        with st.spinner(f"æ­£åœ¨ä½¿ç”¨{strategy_name}ç­–ç•¥é‡åˆ†ç±»ç¦»ç¾¤å€¼..."):
            new_topics, report = reduce_outliers(model, topics, strategy=strategy_name, threshold=threshold)
        
        st.markdown("---")
        
        st.write("**é‡åˆ†ç±»ç»“æœ**:")
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        if report:
            if 'error' in report:
                st.error(f"âŒ é”™è¯¯: {report['error']}")
            else:
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("é‡åˆ†ç±»å‰ç¦»ç¾¤å€¼", report['é‡åˆ†ç±»å‰å™ªå£°æ•°'])
                
                with col2:
                    st.metric("é‡åˆ†ç±»åç¦»ç¾¤å€¼", report['é‡åˆ†ç±»åå™ªå£°æ•°'])
                
                with col3:
                    st.metric("æ–°å¢åˆ†é…æ•°", report['é‡æ–°åˆ†é…æ•°'])
                
                with col4:
                    st.metric("æ”¹è¿›ç‡", report['æ”¹è¿›ç‡'])
                
                st.markdown("---")
                
                # æ˜¾ç¤ºè¯¦ç»†æŠ¥å‘Š
                report_df = pd.DataFrame([report])
                st.dataframe(report_df, use_container_width=True)
                
                st.markdown("---")
                
                # é€‰é¡¹ï¼šä¿å­˜æ–°çš„topics
                if report['é‡æ–°åˆ†é…æ•°'] > 0:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if st.button("âœ… ä¿å­˜ä¸ºsession stateï¼ˆå½“å‰ä¼šè¯ï¼‰", key="save_topics"):
                            st.session_state.reduced_topics = new_topics
                            st.success("âœ… å·²ä¿å­˜ï¼Œå¯åœ¨å…¶ä»–åˆ†æä¸­ä½¿ç”¨")
                    
                    with col2:
                        if st.button("ğŸ“¥ ä¸‹è½½å¤„ç†åçš„topicsæ•°ç»„", key="download_topics"):
                            topics_csv = pd.DataFrame({
                                'document_index': range(len(new_topics)),
                                'topic_id': new_topics
                            })
                            csv = topics_csv.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                label="ç‚¹å‡»ä¸‹è½½ topics.csv",
                                data=csv,
                                file_name="reduced_topics.csv",
                                mime="text/csv"
                            )
    
    st.markdown("---")
    
    st.info("""
    ğŸ’¡ **å¦‚ä½•ç†è§£ç¦»ç¾¤å€¼å¤„ç†**:
    - Noise(æ ‡ç­¾-1)ï¼šæ— æ³•æ¸…æ™°åˆ†é…åˆ°ä»»ä½•ä¸»é¢˜çš„æ–‡æ¡£
    - é‡åˆ†ç±»ï¼šå°è¯•æŠŠNoiseåˆ†é…åˆ°æœ€åˆé€‚çš„ä¸»é¢˜
    - ç­–ç•¥é€‰æ‹©ï¼šé€Ÿåº¦å’Œç²¾åº¦çš„å¹³è¡¡
    
    **å¯è§£é‡Šæ€§ä»·å€¼**:
    âœ“ æé«˜æ•°æ®åˆ©ç”¨ç‡ï¼ˆå‡å°‘"æœªåˆ†ç±»"ï¼‰
    âœ“ å®Œæ•´è¦†ç›–ï¼ˆè·å¾—æ›´å®Œæ•´çš„ä¸»é¢˜åˆ†å¸ƒï¼‰
    âœ“ æ•°æ®è´¨é‡æ”¹è¿›ï¼ˆå¯æ‰‹åŠ¨å®¡æ ¸é‡åˆ†é…ç»“æœï¼‰
    
    **4ç§ç­–ç•¥å¯¹æ¯”**:
    | ç­–ç•¥ | é€Ÿåº¦ | ç²¾åº¦ | ä½•æ—¶ç”¨ |
    |------|------|------|--------|
    | probabilities | ä¸­ | é«˜ | æ¨èé»˜è®¤ |
    | distributions | å¿« | ä¸­ | å¤§æ•°æ® |
    | c-tf-idf | å¾ˆå¿« | ä¸­ | å¿«é€Ÿè¯•éªŒ |
    | embeddings | æ…¢ | å¾ˆé«˜ | å°æ•°æ®é›† |
    """)

# ============================================================================
# Tab 4: è‡ªå®šä¹‰ä¸»é¢˜æ ‡ç­¾è®¾ç½® (F104)
# ============================================================================
with tab4:
     st.subheader("ğŸ·ï¸ è‡ªå®šä¹‰ä¸»é¢˜æ ‡ç­¾è®¾ç½® (F104)")
     st.write("ä¸ºä¸»é¢˜æŒ‡å®šæœ‰æ„ä¹‰çš„è‡ªå®šä¹‰åç§°ï¼Œæ›¿æ¢è‡ªåŠ¨ç”Ÿæˆçš„æ ‡ç­¾")
     
     st.markdown("---")
     
     # æ˜¾ç¤ºå½“å‰ä¸»é¢˜æ ‡ç­¾
     topic_info = get_topics_summary(model)
     
     if not topic_info.empty:
         st.write("**å½“å‰ä¸»é¢˜æ ‡ç­¾**:")
         st.dataframe(topic_info[topic_info['Topic'] != -1], use_container_width=True)
         
         st.markdown("---")
         
         st.write("**è‡ªå®šä¹‰æ ‡ç­¾ç¼–è¾‘**:")
         st.write("è¾“å…¥JSONæ ¼å¼çš„æ ‡ç­¾æ˜ å°„ï¼Œæˆ–ä½¿ç”¨ä¸‹é¢çš„è¡¨å•")
         
         col1, col2 = st.columns([1, 1])
         
         with col1:
             st.write("**é€‰é¡¹1: JSONæ ¼å¼è¾“å…¥**")
             st.write("ä¾‹: {0: \"ç”¨æˆ·ä½“éªŒ\", 1: \"äº§å“è´¨é‡\", 2: \"é…é€é€Ÿåº¦\"}")
             
             json_input = st.text_area(
                 "è¾“å…¥æ ‡ç­¾JSONï¼ˆä»…åŒ…å«è¦æ›´æ–°çš„ä¸»é¢˜ï¼‰",
                 value="{}",
                 height=150,
                 key="json_labels"
             )
         
         with col2:
             st.write("**é€‰é¡¹2: è¡¨å•ç¼–è¾‘**")
             
             label_dict = {}
             
             # ä¸ºæ¯ä¸ªéå™ªå£°ä¸»é¢˜åˆ›å»ºç¼–è¾‘æ¡†
             for _, row in topic_info[topic_info['Topic'] != -1].iterrows():
                 topic_id = int(row['Topic'])
                 current_name = row['Name']
                 
                 new_label = st.text_input(
                     f"è¯é¢˜{topic_id}",
                     value=current_name,
                     key=f"label_topic_{topic_id}"
                 )
                 
                 if new_label != current_name:
                     label_dict[topic_id] = new_label
         
         st.markdown("---")
         
         # å¤„ç†JSONè¾“å…¥
         if st.button("ğŸš€ åº”ç”¨è‡ªå®šä¹‰æ ‡ç­¾", key="apply_labels_btn"):
             try:
                 # ä¼˜å…ˆä½¿ç”¨JSONè¾“å…¥ï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨è¡¨å•è¾“å…¥
                 if json_input.strip() != "{}":
                     import json
                     json_dict = json.loads(json_input)
                     label_dict.update(json_dict)
                 
                 if label_dict:
                     with st.spinner("æ­£åœ¨åº”ç”¨è‡ªå®šä¹‰æ ‡ç­¾..."):
                         updated_model, result = set_topic_labels(model, label_dict)
                         model = updated_model
                     
                     if result['status'] == 'æˆåŠŸ':
                         st.success(f"âœ… {result['message']}")
                         st.info("ğŸ’¡ åˆ·æ–°é¡µé¢ä»¥æŸ¥çœ‹æ›´æ–°åçš„æ ‡ç­¾æ•ˆæœ")
                     else:
                         st.error(f"âŒ {result['message']}")
                 else:
                     st.warning("âš ï¸ è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè‡ªå®šä¹‰æ ‡ç­¾")
             
             except Exception as e:
                 st.error(f"âŒ æ ‡ç­¾åº”ç”¨å¤±è´¥: {e}")
         
         st.markdown("---")
         
         st.info("""
         ğŸ’¡ **è‡ªå®šä¹‰æ ‡ç­¾çš„ç”¨é€”**:
         - æé«˜å¯è¯»æ€§ï¼šç”¨ä¸šåŠ¡æœ¯è¯­æ›¿æ¢è‡ªåŠ¨æ ‡ç­¾
         - ä¸€è‡´æ€§ï¼šä¸å…¬å¸æˆ–é¢†åŸŸçš„æ ‡å‡†æœ¯è¯­å¯¹é½
         - æ–‡æ¡£åŒ–ï¼šä¸ºåç»­åˆ†ææä¾›æ¸…æ™°çš„æ ‡ç­¾
         
         **ä½¿ç”¨å»ºè®®**:
         1. å®¡æŸ¥è‡ªåŠ¨ç”Ÿæˆçš„æ ‡ç­¾
         2. æ ¹æ®è¯é¢˜è¯çš„å…³é”®è¯å«ä¹‰æ”¹è¿›æ ‡ç­¾
         3. ä¿æŒæ ‡ç­¾ç®€æ´ï¼ˆ5ä¸ªå­—ä»¥å†…ï¼‰
         4. ä½¿ç”¨ä¸šåŠ¡ç›¸å…³çš„æœ¯è¯­
         """)
     else:
         st.warning("âš ï¸ æ— æ³•åŠ è½½ä¸»é¢˜ä¿¡æ¯")

# ============================================================================
# Tab 5: å¤šä¸»é¢˜è¯æƒé‡å¯¹æ¯” (F105)
# ============================================================================
with tab5:
     st.subheader("ğŸ“Š å¤šä¸»é¢˜è¯æƒé‡å¯¹æ¯” (F105)")
     st.write("å¹¶è¡Œæ˜¾ç¤ºå¤šä¸ªä¸»é¢˜çš„Topè¯åŠå…¶æƒé‡ï¼Œä¾¿äºè¿›è¡Œä¸»é¢˜å¯¹æ¯”åˆ†æ")
     
     st.markdown("---")
     
     col1, col2 = st.columns([1, 1])
     
     with col1:
         top_n_topics = st.slider(
             "æ˜¾ç¤ºå¤šå°‘ä¸ªä¸»é¢˜",
             2, min(10, len(np.unique(topics)) - 1), 5,
             help="é€‰æ‹©è¦å¯¹æ¯”çš„ä¸»é¢˜æ•°é‡",
             key="f105_topics"
         )
     
     with col2:
         top_n_words = st.slider(
             "æ¯ä¸ªä¸»é¢˜æ˜¾ç¤ºå¤šå°‘ä¸ªTopè¯",
             3, 15, 10,
             help="æ¯ä¸ªä¸»é¢˜çš„å…³é”®è¯æ•°é‡",
             key="f105_words"
         )
     
     st.markdown("---")
     
     if st.button("ğŸ”„ ç”Ÿæˆè¯æƒé‡å¯¹æ¯”å›¾", key="gen_barchart_btn"):
         with st.spinner("æ­£åœ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨..."):
             fig = visualize_barchart_comparison(model, top_n_topics=top_n_topics, top_n_words=top_n_words)
         
         if fig:
             st.plotly_chart(fig, use_container_width=True)
             
             st.markdown("---")
             
             st.info("""
             ğŸ’¡ **å¦‚ä½•è§£è¯»å¯¹æ¯”å›¾**:
             - Xè½´ï¼šå…³é”®è¯æ’åºï¼ˆè¶Šé å‰æƒé‡è¶Šé«˜ï¼‰
             - Yè½´ï¼šc-TF-IDFæƒé‡åˆ†æ•°
             - å¤šä¸ªä¸»é¢˜å¹¶æ’æ˜¾ç¤ºï¼Œä¾¿äºå¯¹æ¯”
             - é«˜æƒé‡è¯æ˜¯è¯¥ä¸»é¢˜çš„"ä»£è¡¨è¯"
             
             **å¯ç”¨äº**:
             âœ“ ç†è§£ä¸åŒä¸»é¢˜çš„æ ¸å¿ƒå…³æ³¨ç‚¹
             âœ“ è¯†åˆ«ç›¸ä¼¼ä¸»é¢˜ï¼ˆè¯æ±‡é‡å å¾ˆå¤šï¼‰
             âœ“ å‘ç°ä¸»é¢˜ä¹‹é—´çš„å·®å¼‚å’Œå…³è”
             âœ“ æ‰‹åŠ¨éªŒè¯ä¸»é¢˜å»ºæ¨¡æ•ˆæœ
             """)
         else:
             st.warning("âš ï¸ å¯¹æ¯”å›¾ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–æ¨¡å‹é…ç½®")

# ============================================================================
# Tab 6: å…³é”®è¯ä¸»é¢˜æœç´¢ (F106)
# ============================================================================
with tab6:
     st.subheader("ğŸ” å…³é”®è¯ä¸»é¢˜æœç´¢ (F106)")
     st.write("è¾“å…¥å…³é”®è¯ï¼Œè‡ªåŠ¨æŸ¥æ‰¾åŒ…å«è¿™äº›è¯æ±‡çš„ç›¸å…³ä¸»é¢˜")
     
     st.markdown("---")
     
     # å…³é”®è¯è¾“å…¥
     col1, col2 = st.columns([2, 1])
     
     with col1:
         keywords_input = st.text_input(
             "è¾“å…¥æœç´¢å…³é”®è¯ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
             value="ç”¨æˆ·,æœåŠ¡,äº§å“",
             placeholder="ä¾‹: ç”¨æˆ·,æœåŠ¡,äº§å“",
             key="search_keywords"
         )
     
     with col2:
         top_n_results = st.slider(
             "è¿”å›æ’åå‰Nä¸ªä¸»é¢˜",
             1, 10, 5,
             key="f106_top_n"
         )
     
     st.markdown("---")
     
     # æ‰§è¡Œæœç´¢
     if st.button("ğŸš€ æœç´¢ç›¸å…³ä¸»é¢˜", key="search_topics_btn"):
         # è§£æå…³é”®è¯
         keywords = [kw.strip() for kw in keywords_input.split(',') if kw.strip()]
         
         if keywords:
             with st.spinner(f"æ­£åœ¨æœç´¢åŒ…å« {keywords} çš„ä¸»é¢˜..."):
                 results_df = search_topics(model, keywords, top_n=top_n_results)
             
             if not results_df.empty:
                 st.success(f"âœ… æ‰¾åˆ°{len(results_df)}ä¸ªç›¸å…³ä¸»é¢˜")
                 
                 st.markdown("---")
                 
                 st.write("**æœç´¢ç»“æœ**:")
                 st.dataframe(results_df, use_container_width=True)
                 
                 st.markdown("---")
                 
                 # è¯¦ç»†å±•ç¤ºæ¯ä¸ªä¸»é¢˜
                 st.write("**è¯¦ç»†ä¿¡æ¯**:")
                 
                 for idx, row in results_df.iterrows():
                     with st.expander(f"ğŸ“Œ {row['ä¸»é¢˜åç§°']} (ç›¸å…³æ€§: {row['å¹³å‡ç›¸å…³æ€§']})"):
                         col1, col2, col3 = st.columns(3)
                         
                         with col1:
                             st.metric("ä¸»é¢˜ID", int(row['ä¸»é¢˜ID']))
                         
                         with col2:
                             st.metric("åŒ¹é…è¯æ•°", len(row['åŒ¹é…è¯'].split(',')))
                         
                         with col3:
                             st.metric("åŒ…å«æ–‡æ¡£æ•°", row['æ–‡æ¡£æ•°'])
                         
                         st.write(f"**åŒ¹é…è¯**: {row['åŒ¹é…è¯']}")
             else:
                 st.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ…å« {keywords} çš„ç›¸å…³ä¸»é¢˜")
         else:
             st.error("âŒ è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªå…³é”®è¯")
     
     st.markdown("---")
     
     st.info("""
     ğŸ’¡ **å…³é”®è¯æœç´¢çš„åº”ç”¨åœºæ™¯**:
     - å¿«é€Ÿå®šä½ç‰¹å®šè¯é¢˜ï¼ˆå¦‚"ç‰©æµ"ã€"å”®å"ï¼‰
     - å‘ç°æ½œåœ¨çš„ä¸»é¢˜èšç±»ï¼ˆç›¸ä¼¼è¯å‡ºç°åœ¨å¤šä¸ªä¸»é¢˜ä¸­ï¼‰
     - è´¨é‡æ£€æŸ¥ï¼šéªŒè¯è‡ªåŠ¨æ ‡ç­¾æ˜¯å¦å‡†ç¡®
     - ä¸šåŠ¡å¯¼å‘ï¼šæ ¹æ®è¿è¥å…³é”®è¯æŸ¥æ‰¾ç›¸å…³æ„è§
     
     **æœç´¢ç­–ç•¥**:
     âœ“ ä½¿ç”¨è¡Œä¸šæœ¯è¯­æˆ–å¸¸è§ä¸šåŠ¡è¯æ±‡
     âœ“ é€ä¸ªå…³é”®è¯æœç´¢ï¼Œå†ç»„åˆæœç´¢
     âœ“ ä½¿ç”¨æœç´¢ç»“æœæŒ‡å¯¼ä¸»é¢˜æ ‡ç­¾ä¼˜åŒ–
     """)

st.markdown("---")

st.subheader("ğŸ“Š Phase 4-5 åŠŸèƒ½æ€»è§ˆ")

st.markdown("""
### âœ… å·²å®ç°çš„6ä¸ªåŠŸèƒ½

| åŠŸèƒ½ID | åŠŸèƒ½åç§° | æ‰€åœ¨ä½ç½® | ç”¨é€” |
|--------|--------|--------|------|
| **F101** | å•æ–‡æ¡£ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒ | Tab1 | ç†è§£æ¨¡å‹å¯¹å•æ¡æ„è§çš„åˆ¤æ–­ï¼Œè°ƒè¯•ç½®ä¿¡åº¦ |
| **F102** | Tokençº§ä¸»é¢˜åˆ†æ | Tab2 | çœ‹æ¸…AIçš„"è§†è§’"ï¼Œè¯†åˆ«å…³é”®è§¦å‘è¯ |
| **F103** | ç¦»ç¾¤å€¼è‡ªåŠ¨é‡åˆ†ç±» | Tab3 | æé«˜æ•°æ®åˆ©ç”¨ç‡ï¼Œæ”¹è¿›ä¸»é¢˜è¦†ç›– |
| **F104** | è‡ªå®šä¹‰ä¸»é¢˜æ ‡ç­¾è®¾ç½® | Tab4 | ç”¨ä¸šåŠ¡æœ¯è¯­å®šåˆ¶æ ‡ç­¾ï¼Œæé«˜å¯è¯»æ€§ |
| **F105** | å¤šä¸»é¢˜è¯æƒé‡å¯¹æ¯” | Tab5 | å¹¶è¡Œå¯¹æ¯”ä¸»é¢˜ç‰¹å¾ï¼Œè¯†åˆ«ç›¸ä¼¼ä¸»é¢˜ |
| **F106** | å…³é”®è¯ä¸»é¢˜æœç´¢ | Tab6 | å¿«é€Ÿå®šä½ç‰¹å®šè¯é¢˜ï¼Œè´¨é‡æ£€æŸ¥ |

### åç»­è®¡åˆ’

**Phase 6** (å¯é€‰): F107-F109
- F107: è®ºæ–‡çº§é™æ€å›¾å¯¼å‡ºï¼ˆé«˜åˆ†è¾¨ç‡PNG/PDFï¼‰
- F108: ä¸»é¢˜è¡¨ç¤ºä¼˜åŒ–ï¼ˆæ›´æ–°ä¸»é¢˜åç§°ç”Ÿæˆæ¨¡å‹ï¼‰
- F109: ä¸»é¢˜ä»£è¡¨æ–‡æ¡£æå–ï¼ˆæ¯ä¸ªä¸»é¢˜æ˜¾ç¤ºtop3ä»£è¡¨æ–‡æ¡£ï¼‰

---

ğŸ’¡ **æ¨èä½¿ç”¨é¡ºåº**:
1. **ç¬¬ä¸€æ­¥**: Tab1-3ï¼ˆç†è§£ã€åˆ†æã€æ¸…ç†æ•°æ®ï¼‰
2. **ç¬¬äºŒæ­¥**: Tab4-6ï¼ˆä¼˜åŒ–æ ‡ç­¾ã€å¯¹æ¯”åˆ†æã€å¿«é€Ÿæœç´¢ï¼‰
3. **è¾“å‡º**: å‘å¸ƒåˆ°P7è¿›è¡Œå…¨é¢å±•ç¤º

**å®Œæ•´å·¥ä½œæµ**:
- ä½¿ç”¨F101/F102ç†è§£å•ä¸ªæ„è§çš„åˆ†ç±»é€»è¾‘
- ç”¨F103æ”¹è¿›æ•°æ®è´¨é‡ï¼ˆå‡å°‘å™ªå£°ï¼‰
- ç”¨F104å®šåˆ¶ä¸šåŠ¡ç›¸å…³çš„æ ‡ç­¾
- ç”¨F105/F106è¿›è¡Œå¯¹æ¯”å’ŒéªŒè¯
- æœ€åè¾“å‡ºåˆ°P7_è¯é¢˜çƒ­åº¦æ•æ„Ÿåº¦åˆ†æé¡µé¢å±•ç¤º

**æŠ€æœ¯è¦æ±‚**: BERTopicå·²å¯ç”¨ `calculate_probabilities=True`
""")
