"""
äº’åŠ¨åˆ†æå·¥å…·é¡µé¢ - Phase 4 å¯è§£é‡Šæ€§åŠŸèƒ½
BERTopic F101-F103: å•æ–‡æ¡£åˆ†æã€Tokençº§åˆ†æã€ç¦»ç¾¤å€¼å¤„ç†
"""

import streamlit as st
import pandas as pd
import numpy as np
from utils.data_loader import (
    load_analysis_data,
    translate_sentiment,
    translate_risk,
    translate_topic
)
from utils.bertopic_analyzer import (
    train_bertopic,
    visualize_distribution,
    visualize_approximate_distribution,
    reduce_outliers,
    get_topics_summary,
    set_topic_labels,
    visualize_barchart_comparison,
    search_topics,
    get_representative_documents,
    get_all_topics_representative_docs,
    visualize_topics_2d,
    visualize_topic_hierarchy,
    visualize_topic_similarity,
    visualize_term_distribution,
    visualize_topic_per_class,
    export_visualization_to_file,
    batch_export_visualizations,
    create_summary_report,
    BERTOPIC_AVAILABLE
)

st.set_page_config(page_title="äº’åŠ¨åˆ†æå·¥å…·", page_icon="ğŸ”®", layout="wide")

st.title("ğŸ”® äº’åŠ¨åˆ†æå·¥å…· (Phase 4)")
st.write("ä½¿ç”¨BERTopicçš„é«˜çº§äº¤äº’åŠŸèƒ½ï¼Œæ·±å…¥ç†è§£AIçš„å†³ç­–è¿‡ç¨‹")

if not BERTOPIC_AVAILABLE:
    st.error("âš ï¸ BERTopicæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨äº’åŠ¨åˆ†æå·¥å…·")
    st.stop()

def load_data():
    return load_analysis_data()

df = load_data()

# è®­ç»ƒæ¨¡å‹ï¼ˆç¼“å­˜ç»“æœä»¥åŠ é€Ÿï¼‰
with st.spinner("ğŸ¤– åˆå§‹åŒ–BERTopicæ¨¡å‹..."):
    texts = df['source_text'].tolist()
    topics, probs, model = train_bertopic(texts)

if model is None or topics is None:
    st.error("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
    st.stop()

st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼å‘ç°{len(np.unique(topics))-1}ä¸ªéšè—ä¸»é¢˜")

st.markdown("---")

# åˆ›å»º8ä¸ªTab
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
    "ğŸ“„ å•æ–‡æ¡£ä¸»é¢˜åˆ†æ",
    "ğŸ”¤ Tokençº§è¯åˆ†æ",
    "ğŸ§¹ ç¦»ç¾¤å€¼å¤„ç†",
    "ğŸ·ï¸ è‡ªå®šä¹‰æ ‡ç­¾",
    "ğŸ“Š è¯æƒé‡å¯¹æ¯”",
    "ğŸ” å…³é”®è¯æœç´¢",
    "â­ ä»£è¡¨æ–‡æ¡£",
    "ğŸ’¾ å¯¼å‡ºæŠ¥å‘Š"
])

# ============================================================================
# Tab 1: å•æ–‡æ¡£ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒ (F101)
# ============================================================================
with tab1:
    st.subheader("ğŸ“„ å•æ–‡æ¡£ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒåˆ†æ (F101)")
    st.write("é€‰æ‹©ä¸€æ¡æ„è§ï¼ŒæŸ¥çœ‹AIå¦‚ä½•åˆ†é…å„ä¸»é¢˜æ¦‚ç‡ï¼Œç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # æ–‡æ¡£é€‰æ‹©
        doc_selector = st.slider(
            "é€‰æ‹©æ–‡æ¡£",
            0, len(df) - 1, 0,
            help="æ»‘åŠ¨é€‰æ‹©è¦åˆ†æçš„æ–‡æ¡£ç´¢å¼•"
        )
    
    with col2:
        st.metric("å½“å‰æ–‡æ¡£", f"#{doc_selector}")
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ–‡æ¡£å†…å®¹
    selected_doc = df.iloc[doc_selector]
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.write("**åŸæ–‡å†…å®¹**:")
        st.markdown(f"> {selected_doc['source_text']}")
    
    with col2:
        st.write("**æ–‡æ¡£å±æ€§**:")
        st.write(f"æƒ…æ„Ÿ: {translate_sentiment(selected_doc['sentiment'])}")
        st.write(f"é£é™©: {translate_risk(selected_doc['risk_level'])}")
        st.write(f"è¯é¢˜: {translate_topic(selected_doc['topic'])}")
    
    st.markdown("---")
    
    # ç”Ÿæˆæ¦‚ç‡åˆ†å¸ƒå¯è§†åŒ–
    st.write("**ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒ**:")
    st.write("ä¸‹å›¾å±•ç¤ºè¯¥æ–‡æ¡£å±äºå„ä¸»é¢˜çš„ç½®ä¿¡åº¦ï¼ˆä»…æ˜¾ç¤º>1.5%çš„ä¸»é¢˜ï¼‰")
    
    min_prob = st.slider("æœ€å°æ¦‚ç‡é˜ˆå€¼", 0.0, 0.1, 0.015, 0.005, key="f101_prob")
    
    viz = visualize_distribution(model, doc_selector, min_probability=min_prob)
    if viz:
        st.plotly_chart(viz, use_container_width=True)
    else:
        st.warning("âš ï¸ æ— æ³•ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ¨¡å‹å¯èƒ½æœªå¯ç”¨calculate_probabilities=Trueï¼‰")
    
    st.markdown("---")
    
    st.info("""
    ğŸ’¡ **å¦‚ä½•ç†è§£è¿™ä¸ªå›¾**:
    - Xè½´: æ–‡æ¡£å¯èƒ½å±äºçš„å„ä¸ªä¸»é¢˜
    - Yè½´: æ¦‚ç‡ï¼ˆ0-1ï¼‰
    - æŸ±å­é«˜åº¦è¶Šé«˜ï¼Œè¯´æ˜æ¨¡å‹è¶Šç¡®ä¿¡è¯¥æ–‡æ¡£å±äºè¯¥ä¸»é¢˜
    - æ¦‚ç‡åˆ†æ•£ = æ–‡æ¡£æ¶‰åŠå¤šä¸ªä¸»é¢˜ï¼›æ¦‚ç‡é›†ä¸­ = æ–‡æ¡£ä¸»é¢˜æ˜ç¡®
    
    **å¯è§£é‡Šæ€§ä»·å€¼**:
    âœ“ ç†è§£æ¨¡å‹å¯¹å•æ¡æ„è§çš„åˆ¤æ–­ä¿¡å¿ƒ
    âœ“ è¯†åˆ«å¤šä¸»é¢˜æ–‡æ¡£ï¼ˆæ¦‚ç‡åˆ†æ•£çš„æƒ…å†µï¼‰
    âœ“ è°ƒè¯•æ¨¡å‹ç½®ä¿¡åº¦ï¼Œå‘ç°å¼‚å¸¸åˆ†ç±»
    """)

# ============================================================================
# Tab 2: Tokençº§ä¸»é¢˜åˆ†æ (F102)
# ============================================================================
with tab2:
    st.subheader("ğŸ”¤ Tokençº§è¯ä¸»é¢˜åˆ†æ (F102)")
    st.write("ç²¾ç¡®åˆ°å•è¯çº§åˆ«ï¼Œçœ‹å“ªäº›å…³é”®è¯è§¦å‘äº†å“ªä¸ªä¸»é¢˜")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        doc_selector2 = st.slider(
            "é€‰æ‹©æ–‡æ¡£è¿›è¡Œè¯çº§åˆ†æ",
            0, len(df) - 1, 0,
            help="é€‰æ‹©è¦åˆ†æçš„æ–‡æ¡£",
            key="f102_doc"
        )
    
    with col2:
        st.metric("å½“å‰æ–‡æ¡£", f"#{doc_selector2}")
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ–‡æ¡£å†…å®¹
    selected_doc2 = df.iloc[doc_selector2]
    
    st.write("**å¾…åˆ†ææ–‡æ¡£**:")
    st.markdown(f"> {selected_doc2['source_text']}")
    
    st.markdown("---")
    
    # ç”ŸæˆTokençº§åˆ†å¸ƒ
    st.write("**è¯çº§ä¸»é¢˜åˆ†å¸ƒ**:")
    st.write("ä»¥ä¸‹è¡¨æ ¼å±•ç¤ºæ¯ä¸ªè¯æœ€å¯èƒ½å±äºçš„ä¸»é¢˜åŠç½®ä¿¡åº¦")
    
    result = visualize_approximate_distribution(model, texts, doc_selector2, calculate_tokens=True)
    
    if result and isinstance(result, dict):
        # æ˜¾ç¤ºä¸»é¢˜çº§åˆ†å¸ƒ
        if 'ä¸»é¢˜åˆ†å¸ƒ' in result:
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.write("**ä¸»é¢˜çº§æ¦‚ç‡åˆ†å¸ƒ**:")
                st.dataframe(result['ä¸»é¢˜åˆ†å¸ƒ'], use_container_width=True)
            
            with col2:
                st.write("**è¯çº§åˆ†å¸ƒ**:")
                if 'è¯çº§åˆ†å¸ƒ' in result:
                    st.dataframe(result['è¯çº§åˆ†å¸ƒ'], use_container_width=True)
                else:
                    st.info("ğŸ’¡ è¯çº§åˆ†å¸ƒè®¡ç®—ä¸­...")
    else:
        st.warning("âš ï¸ æ— æ³•è®¡ç®—Tokençº§åˆ†å¸ƒï¼ˆå¯èƒ½éœ€è¦å¯ç”¨approximate_distributionï¼‰")
    
    st.markdown("---")
    
    st.info("""
    ğŸ’¡ **å¦‚ä½•ç†è§£Tokençº§åˆ†æ**:
    - æ¯ä¸ªè¯éƒ½ä¼šæ¿€æ´»æŸä¸ªä¸»é¢˜ï¼ˆç½®ä¿¡åº¦ï¼‰
    - é«˜ç½®ä¿¡åº¦çš„è¯æ˜¯è¯¥ä¸»é¢˜çš„"å…³é”®è§¦å‘è¯"
    - å¯ç”¨äºç†è§£ä¸ºä»€ä¹ˆè¯¥æ–‡æ¡£è¢«åˆ†åˆ°æŸä¸ªä¸»é¢˜
    
    **å¯è§£é‡Šæ€§ä»·å€¼**:
    âœ“ çœ‹æ¸…AIçš„"è§†è§’" - å“ªäº›è¯æœ€é‡è¦
    âœ“ è´¨é‡æ£€æµ‹ - å‘ç°é”™è¯¯åˆ†ç±»çš„åŸå› 
    âœ“ æ¨¡å‹æ”¹è¿› - è¯†åˆ«éœ€è¦è°ƒæ•´çš„è¯æ±‡æƒé‡
    """)

# ============================================================================
# Tab 3: ç¦»ç¾¤å€¼å¤„ç† (F103)
# ============================================================================
with tab3:
    st.subheader("ğŸ§¹ ç¦»ç¾¤å€¼è‡ªåŠ¨é‡åˆ†ç±» (F103)")
    st.write("å°†æ— æ³•æ¸…æ™°åˆ†ç±»çš„æ–‡æ¡£(Noise=-1)é‡æ–°åˆ†é…åˆ°åˆé€‚ä¸»é¢˜")
    
    st.markdown("---")
    
    # å½“å‰ç»Ÿè®¡
    col1, col2, col3 = st.columns(3)
    
    noise_count = np.sum(topics == -1)
    total_count = len(topics)
    noise_pct = noise_count / total_count * 100 if total_count > 0 else 0
    
    with col1:
        st.metric("å½“å‰ç¦»ç¾¤å€¼æ•°é‡", noise_count)
    
    with col2:
        st.metric("ç¦»ç¾¤å€¼å æ¯”", f"{noise_pct:.1f}%")
    
    with col3:
        st.metric("å¯åˆ†é…ä¸»é¢˜æ•°", len(np.unique(topics[topics != -1])))
    
    st.markdown("---")
    
    st.write("**é‡åˆ†ç±»é…ç½®**:")
    
    col1, col2 = st.columns(2)
    
    with col1:
        strategy = st.radio(
            "é€‰æ‹©é‡åˆ†ç±»ç­–ç•¥",
            [
                "probabilities - HDBSCANè½¯èšç±»æ¦‚ç‡ï¼ˆæœ€ç¨³å®šï¼‰",
                "distributions - è¿‘ä¼¼ä¸»é¢˜åˆ†å¸ƒï¼ˆè¾ƒå¿«ï¼‰",
                "c-tf-idf - è¯é¢‘ç›¸ä¼¼åº¦ï¼ˆæœ€å¿«ï¼‰",
                "embeddings - è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆæœ€å‡†ç¡®ä½†æœ€æ…¢ï¼‰"
            ],
            help="ä¸åŒç­–ç•¥çš„ç²¾åº¦å’Œé€Ÿåº¦æƒè¡¡",
            key="reduce_strategy"
        )
        # æå–ç­–ç•¥åç§°
        strategy_name = strategy.split(" - ")[0]
    
    with col2:
        threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            0.05, 0.5, 0.1, 0.05,
            help="åªé‡åˆ†é…ç½®ä¿¡åº¦>é˜ˆå€¼çš„ç¦»ç¾¤å€¼ï¼ˆè¶Šä½è¶Šæ¿€è¿›ï¼‰"
        )
    
    st.markdown("---")
    
    # æ‰§è¡Œé‡åˆ†ç±»
    if st.button("ğŸš€ æ‰§è¡Œé‡åˆ†ç±»", key="reduce_outliers_btn"):
        with st.spinner(f"æ­£åœ¨ä½¿ç”¨{strategy_name}ç­–ç•¥é‡åˆ†ç±»ç¦»ç¾¤å€¼..."):
            new_topics, report = reduce_outliers(model, topics, strategy=strategy_name, threshold=threshold)
        
        st.markdown("---")
        
        st.write("**é‡åˆ†ç±»ç»“æœ**:")
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        if report:
            if 'error' in report:
                st.error(f"âŒ é”™è¯¯: {report['error']}")
            else:
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("é‡åˆ†ç±»å‰ç¦»ç¾¤å€¼", report['é‡åˆ†ç±»å‰å™ªå£°æ•°'])
                
                with col2:
                    st.metric("é‡åˆ†ç±»åç¦»ç¾¤å€¼", report['é‡åˆ†ç±»åå™ªå£°æ•°'])
                
                with col3:
                    st.metric("æ–°å¢åˆ†é…æ•°", report['é‡æ–°åˆ†é…æ•°'])
                
                with col4:
                    st.metric("æ”¹è¿›ç‡", report['æ”¹è¿›ç‡'])
                
                st.markdown("---")
                
                # æ˜¾ç¤ºè¯¦ç»†æŠ¥å‘Š
                report_df = pd.DataFrame([report])
                st.dataframe(report_df, use_container_width=True)
                
                st.markdown("---")
                
                # é€‰é¡¹ï¼šä¿å­˜æ–°çš„topics
                if report['é‡æ–°åˆ†é…æ•°'] > 0:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if st.button("âœ… ä¿å­˜ä¸ºsession stateï¼ˆå½“å‰ä¼šè¯ï¼‰", key="save_topics"):
                            st.session_state.reduced_topics = new_topics
                            st.success("âœ… å·²ä¿å­˜ï¼Œå¯åœ¨å…¶ä»–åˆ†æä¸­ä½¿ç”¨")
                    
                    with col2:
                        if st.button("ğŸ“¥ ä¸‹è½½å¤„ç†åçš„topicsæ•°ç»„", key="download_topics"):
                            topics_csv = pd.DataFrame({
                                'document_index': range(len(new_topics)),
                                'topic_id': new_topics
                            })
                            csv = topics_csv.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                label="ç‚¹å‡»ä¸‹è½½ topics.csv",
                                data=csv,
                                file_name="reduced_topics.csv",
                                mime="text/csv"
                            )
    
    st.markdown("---")
    
    st.info("""
    ğŸ’¡ **å¦‚ä½•ç†è§£ç¦»ç¾¤å€¼å¤„ç†**:
    - Noise(æ ‡ç­¾-1)ï¼šæ— æ³•æ¸…æ™°åˆ†é…åˆ°ä»»ä½•ä¸»é¢˜çš„æ–‡æ¡£
    - é‡åˆ†ç±»ï¼šå°è¯•æŠŠNoiseåˆ†é…åˆ°æœ€åˆé€‚çš„ä¸»é¢˜
    - ç­–ç•¥é€‰æ‹©ï¼šé€Ÿåº¦å’Œç²¾åº¦çš„å¹³è¡¡
    
    **å¯è§£é‡Šæ€§ä»·å€¼**:
    âœ“ æé«˜æ•°æ®åˆ©ç”¨ç‡ï¼ˆå‡å°‘"æœªåˆ†ç±»"ï¼‰
    âœ“ å®Œæ•´è¦†ç›–ï¼ˆè·å¾—æ›´å®Œæ•´çš„ä¸»é¢˜åˆ†å¸ƒï¼‰
    âœ“ æ•°æ®è´¨é‡æ”¹è¿›ï¼ˆå¯æ‰‹åŠ¨å®¡æ ¸é‡åˆ†é…ç»“æœï¼‰
    
    **4ç§ç­–ç•¥å¯¹æ¯”**:
    | ç­–ç•¥ | é€Ÿåº¦ | ç²¾åº¦ | ä½•æ—¶ç”¨ |
    |------|------|------|--------|
    | probabilities | ä¸­ | é«˜ | æ¨èé»˜è®¤ |
    | distributions | å¿« | ä¸­ | å¤§æ•°æ® |
    | c-tf-idf | å¾ˆå¿« | ä¸­ | å¿«é€Ÿè¯•éªŒ |
    | embeddings | æ…¢ | å¾ˆé«˜ | å°æ•°æ®é›† |
    """)

# ============================================================================
# Tab 4: è‡ªå®šä¹‰ä¸»é¢˜æ ‡ç­¾è®¾ç½® (F104)
# ============================================================================
with tab4:
     st.subheader("ğŸ·ï¸ è‡ªå®šä¹‰ä¸»é¢˜æ ‡ç­¾è®¾ç½® (F104)")
     st.write("ä¸ºä¸»é¢˜æŒ‡å®šæœ‰æ„ä¹‰çš„è‡ªå®šä¹‰åç§°ï¼Œæ›¿æ¢è‡ªåŠ¨ç”Ÿæˆçš„æ ‡ç­¾")
     
     st.markdown("---")
     
     # æ˜¾ç¤ºå½“å‰ä¸»é¢˜æ ‡ç­¾
     topic_info = get_topics_summary(model)
     
     if not topic_info.empty:
         st.write("**å½“å‰ä¸»é¢˜æ ‡ç­¾**:")
         st.dataframe(topic_info[topic_info['Topic'] != -1], use_container_width=True)
         
         st.markdown("---")
         
         st.write("**è‡ªå®šä¹‰æ ‡ç­¾ç¼–è¾‘**:")
         st.write("è¾“å…¥JSONæ ¼å¼çš„æ ‡ç­¾æ˜ å°„ï¼Œæˆ–ä½¿ç”¨ä¸‹é¢çš„è¡¨å•")
         
         col1, col2 = st.columns([1, 1])
         
         with col1:
             st.write("**é€‰é¡¹1: JSONæ ¼å¼è¾“å…¥**")
             st.write("ä¾‹: {0: \"ç”¨æˆ·ä½“éªŒ\", 1: \"äº§å“è´¨é‡\", 2: \"é…é€é€Ÿåº¦\"}")
             
             json_input = st.text_area(
                 "è¾“å…¥æ ‡ç­¾JSONï¼ˆä»…åŒ…å«è¦æ›´æ–°çš„ä¸»é¢˜ï¼‰",
                 value="{}",
                 height=150,
                 key="json_labels"
             )
         
         with col2:
             st.write("**é€‰é¡¹2: è¡¨å•ç¼–è¾‘**")
             
             label_dict = {}
             
             # ä¸ºæ¯ä¸ªéå™ªå£°ä¸»é¢˜åˆ›å»ºç¼–è¾‘æ¡†
             for _, row in topic_info[topic_info['Topic'] != -1].iterrows():
                 topic_id = int(row['Topic'])
                 current_name = row['Name']
                 
                 new_label = st.text_input(
                     f"è¯é¢˜{topic_id}",
                     value=current_name,
                     key=f"label_topic_{topic_id}"
                 )
                 
                 if new_label != current_name:
                     label_dict[topic_id] = new_label
         
         st.markdown("---")
         
         # å¤„ç†JSONè¾“å…¥
         if st.button("ğŸš€ åº”ç”¨è‡ªå®šä¹‰æ ‡ç­¾", key="apply_labels_btn"):
             try:
                 # ä¼˜å…ˆä½¿ç”¨JSONè¾“å…¥ï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨è¡¨å•è¾“å…¥
                 if json_input.strip() != "{}":
                     import json
                     json_dict = json.loads(json_input)
                     label_dict.update(json_dict)
                 
                 if label_dict:
                     with st.spinner("æ­£åœ¨åº”ç”¨è‡ªå®šä¹‰æ ‡ç­¾..."):
                         updated_model, result = set_topic_labels(model, label_dict)
                         model = updated_model
                     
                     if result['status'] == 'æˆåŠŸ':
                         st.success(f"âœ… {result['message']}")
                         st.info("ğŸ’¡ åˆ·æ–°é¡µé¢ä»¥æŸ¥çœ‹æ›´æ–°åçš„æ ‡ç­¾æ•ˆæœ")
                     else:
                         st.error(f"âŒ {result['message']}")
                 else:
                     st.warning("âš ï¸ è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè‡ªå®šä¹‰æ ‡ç­¾")
             
             except Exception as e:
                 st.error(f"âŒ æ ‡ç­¾åº”ç”¨å¤±è´¥: {e}")
         
         st.markdown("---")
         
         st.info("""
         ğŸ’¡ **è‡ªå®šä¹‰æ ‡ç­¾çš„ç”¨é€”**:
         - æé«˜å¯è¯»æ€§ï¼šç”¨ä¸šåŠ¡æœ¯è¯­æ›¿æ¢è‡ªåŠ¨æ ‡ç­¾
         - ä¸€è‡´æ€§ï¼šä¸å…¬å¸æˆ–é¢†åŸŸçš„æ ‡å‡†æœ¯è¯­å¯¹é½
         - æ–‡æ¡£åŒ–ï¼šä¸ºåç»­åˆ†ææä¾›æ¸…æ™°çš„æ ‡ç­¾
         
         **ä½¿ç”¨å»ºè®®**:
         1. å®¡æŸ¥è‡ªåŠ¨ç”Ÿæˆçš„æ ‡ç­¾
         2. æ ¹æ®è¯é¢˜è¯çš„å…³é”®è¯å«ä¹‰æ”¹è¿›æ ‡ç­¾
         3. ä¿æŒæ ‡ç­¾ç®€æ´ï¼ˆ5ä¸ªå­—ä»¥å†…ï¼‰
         4. ä½¿ç”¨ä¸šåŠ¡ç›¸å…³çš„æœ¯è¯­
         """)
     else:
         st.warning("âš ï¸ æ— æ³•åŠ è½½ä¸»é¢˜ä¿¡æ¯")

# ============================================================================
# Tab 5: å¤šä¸»é¢˜è¯æƒé‡å¯¹æ¯” (F105)
# ============================================================================
with tab5:
     st.subheader("ğŸ“Š å¤šä¸»é¢˜è¯æƒé‡å¯¹æ¯” (F105)")
     st.write("å¹¶è¡Œæ˜¾ç¤ºå¤šä¸ªä¸»é¢˜çš„Topè¯åŠå…¶æƒé‡ï¼Œä¾¿äºè¿›è¡Œä¸»é¢˜å¯¹æ¯”åˆ†æ")
     
     st.markdown("---")
     
     col1, col2 = st.columns([1, 1])
     
     with col1:
         top_n_topics = st.slider(
             "æ˜¾ç¤ºå¤šå°‘ä¸ªä¸»é¢˜",
             2, min(10, len(np.unique(topics)) - 1), 5,
             help="é€‰æ‹©è¦å¯¹æ¯”çš„ä¸»é¢˜æ•°é‡",
             key="f105_topics"
         )
     
     with col2:
         top_n_words = st.slider(
             "æ¯ä¸ªä¸»é¢˜æ˜¾ç¤ºå¤šå°‘ä¸ªTopè¯",
             3, 15, 10,
             help="æ¯ä¸ªä¸»é¢˜çš„å…³é”®è¯æ•°é‡",
             key="f105_words"
         )
     
     st.markdown("---")
     
     if st.button("ğŸ”„ ç”Ÿæˆè¯æƒé‡å¯¹æ¯”å›¾", key="gen_barchart_btn"):
         with st.spinner("æ­£åœ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨..."):
             fig = visualize_barchart_comparison(model, top_n_topics=top_n_topics, top_n_words=top_n_words)
         
         if fig:
             st.plotly_chart(fig, use_container_width=True)
             
             st.markdown("---")
             
             st.info("""
             ğŸ’¡ **å¦‚ä½•è§£è¯»å¯¹æ¯”å›¾**:
             - Xè½´ï¼šå…³é”®è¯æ’åºï¼ˆè¶Šé å‰æƒé‡è¶Šé«˜ï¼‰
             - Yè½´ï¼šc-TF-IDFæƒé‡åˆ†æ•°
             - å¤šä¸ªä¸»é¢˜å¹¶æ’æ˜¾ç¤ºï¼Œä¾¿äºå¯¹æ¯”
             - é«˜æƒé‡è¯æ˜¯è¯¥ä¸»é¢˜çš„"ä»£è¡¨è¯"
             
             **å¯ç”¨äº**:
             âœ“ ç†è§£ä¸åŒä¸»é¢˜çš„æ ¸å¿ƒå…³æ³¨ç‚¹
             âœ“ è¯†åˆ«ç›¸ä¼¼ä¸»é¢˜ï¼ˆè¯æ±‡é‡å å¾ˆå¤šï¼‰
             âœ“ å‘ç°ä¸»é¢˜ä¹‹é—´çš„å·®å¼‚å’Œå…³è”
             âœ“ æ‰‹åŠ¨éªŒè¯ä¸»é¢˜å»ºæ¨¡æ•ˆæœ
             """)
         else:
             st.warning("âš ï¸ å¯¹æ¯”å›¾ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–æ¨¡å‹é…ç½®")

# ============================================================================
# Tab 6: å…³é”®è¯ä¸»é¢˜æœç´¢ (F106)
# ============================================================================
with tab6:
     st.subheader("ğŸ” å…³é”®è¯ä¸»é¢˜æœç´¢ (F106)")
     st.write("è¾“å…¥å…³é”®è¯ï¼Œè‡ªåŠ¨æŸ¥æ‰¾åŒ…å«è¿™äº›è¯æ±‡çš„ç›¸å…³ä¸»é¢˜")
     
     st.markdown("---")
     
     # å…³é”®è¯è¾“å…¥
     col1, col2 = st.columns([2, 1])
     
     with col1:
         keywords_input = st.text_input(
             "è¾“å…¥æœç´¢å…³é”®è¯ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
             value="ç”¨æˆ·,æœåŠ¡,äº§å“",
             placeholder="ä¾‹: ç”¨æˆ·,æœåŠ¡,äº§å“",
             key="search_keywords"
         )
     
     with col2:
         top_n_results = st.slider(
             "è¿”å›æ’åå‰Nä¸ªä¸»é¢˜",
             1, 10, 5,
             key="f106_top_n"
         )
     
     st.markdown("---")
     
     # æ‰§è¡Œæœç´¢
     if st.button("ğŸš€ æœç´¢ç›¸å…³ä¸»é¢˜", key="search_topics_btn"):
         # è§£æå…³é”®è¯
         keywords = [kw.strip() for kw in keywords_input.split(',') if kw.strip()]
         
         if keywords:
             with st.spinner(f"æ­£åœ¨æœç´¢åŒ…å« {keywords} çš„ä¸»é¢˜..."):
                 results_df = search_topics(model, keywords, top_n=top_n_results)
             
             if not results_df.empty:
                 st.success(f"âœ… æ‰¾åˆ°{len(results_df)}ä¸ªç›¸å…³ä¸»é¢˜")
                 
                 st.markdown("---")
                 
                 st.write("**æœç´¢ç»“æœ**:")
                 st.dataframe(results_df, use_container_width=True)
                 
                 st.markdown("---")
                 
                 # è¯¦ç»†å±•ç¤ºæ¯ä¸ªä¸»é¢˜
                 st.write("**è¯¦ç»†ä¿¡æ¯**:")
                 
                 for idx, row in results_df.iterrows():
                     with st.expander(f"ğŸ“Œ {row['ä¸»é¢˜åç§°']} (ç›¸å…³æ€§: {row['å¹³å‡ç›¸å…³æ€§']})"):
                         col1, col2, col3 = st.columns(3)
                         
                         with col1:
                             st.metric("ä¸»é¢˜ID", int(row['ä¸»é¢˜ID']))
                         
                         with col2:
                             st.metric("åŒ¹é…è¯æ•°", len(row['åŒ¹é…è¯'].split(',')))
                         
                         with col3:
                             st.metric("åŒ…å«æ–‡æ¡£æ•°", row['æ–‡æ¡£æ•°'])
                         
                         st.write(f"**åŒ¹é…è¯**: {row['åŒ¹é…è¯']}")
             else:
                 st.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ…å« {keywords} çš„ç›¸å…³ä¸»é¢˜")
         else:
             st.error("âŒ è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªå…³é”®è¯")
     
     st.markdown("---")
     
     st.info("""
     ğŸ’¡ **å…³é”®è¯æœç´¢çš„åº”ç”¨åœºæ™¯**:
     - å¿«é€Ÿå®šä½ç‰¹å®šè¯é¢˜ï¼ˆå¦‚"ç‰©æµ"ã€"å”®å"ï¼‰
     - å‘ç°æ½œåœ¨çš„ä¸»é¢˜èšç±»ï¼ˆç›¸ä¼¼è¯å‡ºç°åœ¨å¤šä¸ªä¸»é¢˜ä¸­ï¼‰
     - è´¨é‡æ£€æŸ¥ï¼šéªŒè¯è‡ªåŠ¨æ ‡ç­¾æ˜¯å¦å‡†ç¡®
     - ä¸šåŠ¡å¯¼å‘ï¼šæ ¹æ®è¿è¥å…³é”®è¯æŸ¥æ‰¾ç›¸å…³æ„è§
     
     **æœç´¢ç­–ç•¥**:
     âœ“ ä½¿ç”¨è¡Œä¸šæœ¯è¯­æˆ–å¸¸è§ä¸šåŠ¡è¯æ±‡
     âœ“ é€ä¸ªå…³é”®è¯æœç´¢ï¼Œå†ç»„åˆæœç´¢
     âœ“ ä½¿ç”¨æœç´¢ç»“æœæŒ‡å¯¼ä¸»é¢˜æ ‡ç­¾ä¼˜åŒ–
     """)

# ============================================================================
# Tab 7: ä¸»é¢˜ä»£è¡¨æ–‡æ¡£æå– (F109)
# ============================================================================
with tab7:
     st.subheader("â­ ä¸»é¢˜ä»£è¡¨æ–‡æ¡£æå– (F109)")
     st.write("æŸ¥çœ‹æ¯ä¸ªä¸»é¢˜æœ€å…·ä»£è¡¨æ€§çš„æ„è§ï¼Œå¿«é€Ÿç†è§£ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹")
     
     st.markdown("---")
     
     # ä¸¤ç§æµè§ˆæ¨¡å¼
     col1, col2 = st.columns([1, 1])
     
     with col1:
         mode = st.radio(
             "é€‰æ‹©æµè§ˆæ¨¡å¼",
             ["å•ä¸»é¢˜è¯¦ç»†", "å…¨éƒ¨ä¸»é¢˜æ¦‚è§ˆ"],
             key="f109_mode"
         )
     
     with col2:
         top_n = st.slider(
             "æ¯ä¸ªä¸»é¢˜æ˜¾ç¤ºå¤šå°‘ä¸ªä»£è¡¨æ–‡æ¡£",
             1, 5, 3,
             key="f109_top_n"
         )
     
     st.markdown("---")
     
     if mode == "å•ä¸»é¢˜è¯¦ç»†":
         # æ¨¡å¼1ï¼šå•ä¸»é¢˜è¯¦ç»†æµè§ˆ
         st.write("**é€‰æ‹©ä¸»é¢˜è¿›è¡Œè¯¦ç»†æµè§ˆ**:")
         
         topic_options = {}
         topic_info = get_topics_summary(model)
         
         for _, row in topic_info[topic_info['Topic'] != -1].iterrows():
             topic_id = int(row['Topic'])
             topic_name = row['Name']
             count = row['Count']
             topic_options[f"{topic_name} (è¯é¢˜{topic_id}, {count}æ¡)"] = topic_id
         
         if topic_options:
             selected_option = st.selectbox(
                 "é€‰æ‹©ä¸»é¢˜",
                 list(topic_options.keys()),
                 key="f109_single_topic"
             )
             
             selected_topic_id = topic_options[selected_option]
             
             st.markdown("---")
             
             # è·å–ä»£è¡¨æ–‡æ¡£
             with st.spinner(f"æ­£åœ¨æå–è¯é¢˜{selected_topic_id}çš„ä»£è¡¨æ–‡æ¡£..."):
                 docs_df = get_representative_documents(df, model, topics, selected_topic_id, top_n)
             
             if not docs_df.empty:
                 st.success(f"âœ… æ‰¾åˆ°{len(docs_df)}ä¸ªä»£è¡¨æ–‡æ¡£")
                 
                 st.markdown("---")
                 
                 # é€ä¸ªå±•ç¤ºæ–‡æ¡£
                 for idx, row in docs_df.iterrows():
                     with st.expander(f"ğŸ“Œ #æ’å{row['æ’å']} (ç½®ä¿¡åº¦: {row['ç½®ä¿¡åº¦']}, æ–‡æ¡£ID: {row['æ–‡æ¡£ID']})"):
                         col1, col2, col3 = st.columns([1, 1, 1])
                         
                         with col1:
                             st.write("**æƒ…æ„Ÿ**:")
                             st.write(translate_sentiment(row['æƒ…æ„Ÿ']))
                         
                         with col2:
                             st.write("**é£é™©ç­‰çº§**:")
                             st.write(translate_risk(row['é£é™©']))
                         
                         with col3:
                             st.write("**ç½®ä¿¡åº¦**:")
                             st.write(row['ç½®ä¿¡åº¦'])
                         
                         st.markdown("---")
                         
                         st.write("**å®Œæ•´å†…å®¹**:")
                         st.markdown(f"> {row['å®Œæ•´å†…å®¹']}")
             else:
                 st.warning(f"âš ï¸ è¯¥ä¸»é¢˜æ²¡æœ‰å¯ç”¨çš„ä»£è¡¨æ–‡æ¡£")
         else:
             st.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ä¸»é¢˜")
     
     else:
         # æ¨¡å¼2ï¼šå…¨éƒ¨ä¸»é¢˜æ¦‚è§ˆ
         st.write("**æ‰€æœ‰ä¸»é¢˜çš„ä»£è¡¨æ–‡æ¡£æ¦‚è§ˆ**:")
         
         if st.button("ğŸ”„ ç”Ÿæˆå…¨éƒ¨ä¸»é¢˜çš„ä»£è¡¨æ–‡æ¡£", key="gen_all_docs_btn"):
             with st.spinner("æ­£åœ¨æå–æ‰€æœ‰ä¸»é¢˜çš„ä»£è¡¨æ–‡æ¡£..."):
                 all_docs = get_all_topics_representative_docs(df, model, topics, top_n)
             
             if all_docs:
                 st.success(f"âœ… å·²ç”Ÿæˆ{len(all_docs)}ä¸ªä¸»é¢˜çš„ä»£è¡¨æ–‡æ¡£")
                 
                 st.markdown("---")
                 
                 # é€ä¸ªä¸»é¢˜å±•ç¤º
                 topic_info = get_topics_summary(model)
                 
                 for topic_id in sorted(all_docs.keys()):
                     topic_row = topic_info[topic_info['Topic'] == topic_id]
                     
                     if not topic_row.empty:
                         topic_name = topic_row.iloc[0]['Name']
                         count = topic_row.iloc[0]['Count']
                         
                         with st.expander(f"ğŸ“š {topic_name} (è¯é¢˜{topic_id}, {count}æ¡æ–‡æ¡£)"):
                             docs_df = all_docs[topic_id]
                             
                             # ç®€è¡¨å±•ç¤º
                             st.write("**ä»£è¡¨æ–‡æ¡£åˆ—è¡¨**:")
                             display_df = docs_df[['æ’å', 'å†…å®¹', 'æƒ…æ„Ÿ', 'é£é™©', 'ç½®ä¿¡åº¦']].copy()
                             st.dataframe(display_df, use_container_width=True)
                             
                             st.markdown("---")
                             
                             # è¯¦ç»†å±•ç¤º
                             st.write("**è¯¦ç»†å†…å®¹**:")
                             for _, doc_row in docs_df.iterrows():
                                 col1, col2, col3 = st.columns([2, 1, 1])
                                 
                                 with col1:
                                     st.write(f"**#{doc_row['æ’å']}** {doc_row['å†…å®¹']}")
                                 
                                 with col2:
                                     st.write(f"æƒ…æ„Ÿ: {translate_sentiment(doc_row['æƒ…æ„Ÿ'])}")
                                 
                                 with col3:
                                     st.write(f"ç½®ä¿¡åº¦: {doc_row['ç½®ä¿¡åº¦']}")
             else:
                 st.warning("âš ï¸ æ— æ³•ç”Ÿæˆä»£è¡¨æ–‡æ¡£ï¼ˆå¯èƒ½æ¨¡å‹æœªæ­£ç¡®åˆå§‹åŒ–ï¼‰")
     
     st.markdown("---")
     
     st.info("""
     ğŸ’¡ **ä»£è¡¨æ–‡æ¡£çš„ç”¨é€”**:
     - **å¿«é€Ÿç†è§£ä¸»é¢˜**ï¼šçœ‹å‡ æ¡çœŸå®çš„ç”¨æˆ·æ„è§ï¼Œæ¯”çœ‹è¯æ±‡æ›´ç›´è§‚
     - **è´¨é‡æ£€æŸ¥**ï¼šéªŒè¯ä¸»é¢˜èšç±»æ˜¯å¦æ­£ç¡®ï¼ˆç›¸ä¼¼çš„æ„è§æ˜¯å¦è¢«èšåˆ°åŒä¸€ä¸»é¢˜ï¼‰
     - **ä¸šåŠ¡æ´å¯Ÿ**ï¼šå‘ç°ç”¨æˆ·æœ€å…³å¿ƒçš„å…·ä½“é—®é¢˜
     - **æ•°æ®éªŒè¯**ï¼šæ‰¾å‡ºå¯èƒ½çš„è¯¯åˆ†ç±»ï¼ˆæ„è§å†…å®¹ä¸ä¸»é¢˜æ ‡ç­¾ä¸ç¬¦ï¼‰
     
     **ä½¿ç”¨å»ºè®®**:
     âœ“ å…ˆç”¨å•ä¸»é¢˜æ¨¡å¼æ·±å…¥ç†è§£å„ä¸»é¢˜
     âœ“ å†ç”¨å…¨éƒ¨ä¸»é¢˜æ¦‚è§ˆå¿«é€Ÿæ‰«ä¸€éè´¨é‡
     âœ“ å¦‚æœå‘ç°è¯¯åˆ†ç±»ï¼Œå¯è¿”å›Tab3é‡æ–°å¤„ç†ç¦»ç¾¤å€¼
     âœ“ ç”¨F109çš„åé¦ˆä¼˜åŒ–F104çš„è‡ªå®šä¹‰æ ‡ç­¾
     """)

# ============================================================================
# Tab 8: åˆ†ææŠ¥å‘Šå¯¼å‡º (F107)
# ============================================================================
with tab8:
     st.subheader("ğŸ’¾ åˆ†ææŠ¥å‘Šå¯¼å‡º (F107)")
     st.write("å¯¼å‡ºé«˜åˆ†è¾¨ç‡çš„å¯è§†åŒ–å›¾è¡¨å’Œåˆ†ææŠ¥å‘Šæ‘˜è¦ï¼Œç”¨äºæŠ¥å‘Šå’Œè®ºæ–‡")
     
     st.markdown("---")
     
     # å¯¼å‡ºé…ç½®
     col1, col2, col3 = st.columns(3)
     
     with col1:
         export_format = st.selectbox(
             "é€‰æ‹©å¯¼å‡ºæ ¼å¼",
             ["PNG", "PDF", "SVG", "JPG", "HTML"],
             key="export_format"
         )
     
     with col2:
         dpi = st.selectbox(
             "é€‰æ‹©åˆ†è¾¨ç‡",
             [100, 150, 200, 300, 600],
             index=3,  # é»˜è®¤300 DPI
             help="è¶Šé«˜è¶Šæ¸…æ™°ä½†æ–‡ä»¶è¶Šå¤§ï¼ˆæ¨è300ç”¨äºæ‰“å°ï¼‰",
             key="export_dpi"
         )
     
     with col3:
         width = st.number_input(
             "å›¾è¡¨å®½åº¦(px)",
             300, 2000, 1200,
             step=100,
             key="export_width"
         )
     
     st.markdown("---")
     
     # é€‰æ‹©è¦å¯¼å‡ºçš„å›¾è¡¨
     st.write("**é€‰æ‹©è¦å¯¼å‡ºçš„å¯è§†åŒ–**:")
     
     col1, col2 = st.columns(2)
     
     with col1:
         export_topics_2d = st.checkbox("âœ“ 2Dä¸»é¢˜åˆ†å¸ƒå›¾", value=True, key="export_2d")
         export_similarity = st.checkbox("âœ“ ä¸»é¢˜ç›¸ä¼¼åº¦çƒ­åŠ›å›¾", value=True, key="export_sim")
         export_barchart = st.checkbox("âœ“ è¯æƒé‡å¯¹æ¯”å›¾", value=True, key="export_bar")
     
     with col2:
         export_hierarchy = st.checkbox("âœ“ ä¸»é¢˜å±‚çº§å…³ç³»å›¾", value=False, key="export_hier")
         export_per_class = st.checkbox("âœ“ æŒ‰ç±»åˆ«çš„ä¸»é¢˜åˆ†å¸ƒ", value=True, key="export_class")
         export_report = st.checkbox("âœ“ æ–‡æœ¬æŠ¥å‘Šæ‘˜è¦", value=True, key="export_report")
     
     st.markdown("---")
     
     # å¯¼å‡ºæŒ‰é’®
     if st.button("ğŸš€ ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶", key="gen_exports_btn"):
         with st.spinner("æ­£åœ¨ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶..."):
             # åˆ›å»ºå›¾è¡¨å­—å…¸
             figs_to_export = {}
             
             if export_topics_2d:
                 try:
                     fig_2d = visualize_topics_2d(model, topics)
                     if fig_2d:
                         figs_to_export['1_ä¸»é¢˜2Dåˆ†å¸ƒ'] = fig_2d
                 except:
                     pass
             
             if export_similarity:
                 try:
                     fig_sim = visualize_topic_similarity(model)
                     if fig_sim:
                         figs_to_export['2_ä¸»é¢˜ç›¸ä¼¼åº¦çƒ­åŠ›å›¾'] = fig_sim
                 except:
                     pass
             
             if export_barchart:
                 try:
                     fig_bar = visualize_barchart_comparison(model, top_n_topics=5, top_n_words=10)
                     if fig_bar:
                         figs_to_export['3_è¯æƒé‡å¯¹æ¯”'] = fig_bar
                 except:
                     pass
             
             if export_hierarchy:
                 try:
                     fig_hier = visualize_topic_hierarchy(model)
                     if fig_hier:
                         figs_to_export['4_ä¸»é¢˜å±‚çº§å…³ç³»'] = fig_hier
                 except:
                     pass
             
             if export_per_class:
                 try:
                     fig_class = visualize_topic_per_class(model, df, 'sentiment')
                     if fig_class:
                         figs_to_export['5_æƒ…æ„Ÿç»´åº¦ä¸»é¢˜åˆ†å¸ƒ'] = fig_class
                 except:
                     pass
             
             st.markdown("---")
             
             # å¯¼å‡ºå›¾è¡¨
             if figs_to_export:
                 st.write(f"**å³å°†å¯¼å‡º{len(figs_to_export)}ä¸ªå›¾è¡¨ï¼ˆæ ¼å¼: {export_format}ï¼‰**")
                 
                 exported_files = {}
                 
                 for name, fig in figs_to_export.items():
                     try:
                         file_content = export_visualization_to_file(
                             fig,
                             name,
                             format=export_format.lower(),
                             dpi=dpi,
                             width=width,
                             height=int(width * 0.6)  # 6:10å®½é«˜æ¯”
                         )
                         
                         if file_content:
                             exported_files[name] = file_content
                     except Exception as e:
                         st.warning(f"âš ï¸ {name}å¯¼å‡ºå¤±è´¥: {e}")
                 
                 # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
                 if exported_files:
                     st.success(f"âœ… å·²ç”Ÿæˆ{len(exported_files)}ä¸ªæ–‡ä»¶ï¼Œå¯ä¸‹è½½")
                     
                     st.markdown("---")
                     
                     st.write("**ä¸‹è½½æ–‡ä»¶**:")
                     
                     for name, content in exported_files.items():
                         st.download_button(
                             label=f"ğŸ“¥ ä¸‹è½½ {name}.{export_format.lower()}",
                             data=content,
                             file_name=f"{name}.{export_format.lower()}",
                             mime=f"image/{export_format.lower()}" if export_format.upper() != 'PDF' else "application/pdf"
                         )
             
             st.markdown("---")
             
             # å¯¼å‡ºæŠ¥å‘Šæ–‡æœ¬
             if export_report:
                 st.write("**åˆ†ææŠ¥å‘Šæ‘˜è¦**:")
                 
                 report = create_summary_report(model, df, topics, 
                                              title="ç”µå•†èˆ†è®ºæ•°æ®åˆ†ææŠ¥å‘Š")
                 
                 st.markdown(report)
                 
                 st.markdown("---")
                 
                 # ä¸‹è½½æŠ¥å‘Š
                 report_md = report.encode('utf-8')
                 st.download_button(
                     label="ğŸ“¥ ä¸‹è½½æŠ¥å‘Š (Markdown)",
                     data=report_md,
                     file_name="analysis_report.md",
                     mime="text/markdown"
                 )
     
     st.markdown("---")
     
     st.info("""
     ğŸ’¡ **å¯¼å‡ºåŠŸèƒ½çš„ç”¨é€”**:
     - **è®ºæ–‡å†™ä½œ**ï¼šé«˜åˆ†è¾¨ç‡å›¾è¡¨ç”¨äºå­¦æœ¯æŠ¥å‘Š
     - **æ±‡æŠ¥æ¼”è®²**ï¼šæ¸…æ™°çš„å¯è§†åŒ–ç”¨äºPPTæ¼”ç¤º
     - **å­˜æ¡£è®°å½•**ï¼šä¿å­˜åˆ†æç»“æœä¾›æœªæ¥å‚è€ƒ
     - **è·¨å›¢é˜Ÿå…±äº«**ï¼šé™æ€æ–‡ä»¶ä¾¿äºé‚®ä»¶/æ–‡æ¡£ä¼ è¾“
     
     **æ ¼å¼é€‰æ‹©å»ºè®®**:
     | æ ¼å¼ | ä¼˜ç‚¹ | ç”¨é€” |
     |------|------|------|
     | PNG | æ— æŸï¼Œå¹¿æ³›å…¼å®¹ | ç½‘é¡µã€PPT |
     | PDF | çŸ¢é‡å›¾ï¼Œå¯ç¼–è¾‘æ³¨é‡Š | å­¦æœ¯è®ºæ–‡ã€æ­£å¼æŠ¥å‘Š |
     | SVG | å®Œå…¨çŸ¢é‡ï¼Œç¼©æ”¾æ— æŸ | ä¸“ä¸šå‡ºç‰ˆç‰© |
     | JPG | æ–‡ä»¶å° | å¿«é€Ÿåˆ†äº«ã€ç½‘ç»œä¼ è¾“ |
     | HTML | ä¿ç•™äº¤äº’æ€§ | åœ¨çº¿æŠ¥å‘Š |
     
     **åˆ†è¾¨ç‡å»ºè®®**:
     - å±å¹•å±•ç¤º: 100-150 DPI
     - PPTæ¼”è®²: 200 DPI  
     - å°åˆ·æŠ¥å‘Š: 300+ DPIï¼ˆæ¨èï¼‰
     
     **æŠ€æœ¯è¦æ±‚**: éœ€è¦å®‰è£…kaleidoåº“æ¥å¯¼å‡ºé™æ€å›¾ç‰‡ (`pip install kaleido`)
     """)

st.markdown("---")

st.subheader("ğŸ“Š Phase 4-7 å®Œæ•´åŠŸèƒ½æ€»è§ˆ")

st.markdown("""
### âœ… å·²å®ç°çš„8ä¸ªæ ¸å¿ƒåŠŸèƒ½

| åŠŸèƒ½ID | åŠŸèƒ½åç§° | æ‰€åœ¨ä½ç½® | ç”¨é€” | æŠ€æœ¯éš¾åº¦ |
|--------|--------|--------|------|---------|
| **F101** | å•æ–‡æ¡£ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒ | Tab1 | ç†è§£æ¨¡å‹å¯¹å•æ¡æ„è§çš„åˆ¤æ–­ï¼Œè°ƒè¯•ç½®ä¿¡åº¦ | â­â­ |
| **F102** | Tokençº§ä¸»é¢˜åˆ†æ | Tab2 | çœ‹æ¸…AIçš„"è§†è§’"ï¼Œè¯†åˆ«å…³é”®è§¦å‘è¯ | â­â­â­ |
| **F103** | ç¦»ç¾¤å€¼è‡ªåŠ¨é‡åˆ†ç±» | Tab3 | æé«˜æ•°æ®åˆ©ç”¨ç‡ï¼Œæ”¹è¿›ä¸»é¢˜è¦†ç›– | â­â­â­â­ |
| **F104** | è‡ªå®šä¹‰ä¸»é¢˜æ ‡ç­¾è®¾ç½® | Tab4 | ç”¨ä¸šåŠ¡æœ¯è¯­å®šåˆ¶æ ‡ç­¾ï¼Œæé«˜å¯è¯»æ€§ | â­ |
| **F105** | å¤šä¸»é¢˜è¯æƒé‡å¯¹æ¯” | Tab5 | å¹¶è¡Œå¯¹æ¯”ä¸»é¢˜ç‰¹å¾ï¼Œè¯†åˆ«ç›¸ä¼¼ä¸»é¢˜ | â­â­ |
| **F106** | å…³é”®è¯ä¸»é¢˜æœç´¢ | Tab6 | å¿«é€Ÿå®šä½ç‰¹å®šè¯é¢˜ï¼Œè´¨é‡æ£€æŸ¥ | â­â­â­ |
| **F109** | ä¸»é¢˜ä»£è¡¨æ–‡æ¡£æå– | Tab7 | ç”¨çœŸå®æ„è§ç†è§£ä¸»é¢˜ï¼Œå¿«é€ŸéªŒè¯è´¨é‡ | â­â­ |
| **F107** | è®ºæ–‡çº§æŠ¥å‘Šå¯¼å‡º | Tab8 | å¯¼å‡ºé«˜åˆ†è¾¨ç‡å›¾è¡¨å’ŒæŠ¥å‘Šæ‘˜è¦ | â­â­â­ |

### å¯é€‰å¢å¼º (Phase 8+)

**F108**: ä¸»é¢˜è¡¨ç¤ºä¼˜åŒ–ï¼ˆæ›´æ–°è‡ªåŠ¨ç”Ÿæˆçš„ä¸»é¢˜æ ‡ç­¾åç§°ï¼‰
**F110**: åŠ¨æ€ä»ªè¡¨æ¿ï¼ˆå®æ—¶ä¸»é¢˜ç›‘æ§å’Œé¢„è­¦ï¼‰

---

## ğŸ’¡ å®Œæ•´å·¥ä½œæµï¼ˆæ¨èé¡ºåºï¼‰

```
Step 1: ç†è§£ (Tab1-2)
    â†“
    F101: é€‰æ‹©æ–‡æ¡£ï¼Œçœ‹ä¸»é¢˜æ¦‚ç‡åˆ†å¸ƒ
    F102: çœ‹Tokençº§è¯åˆ†æï¼Œç†è§£è§¦å‘è¯
    â†“
Step 2: æ¸…ç† (Tab3)
    â†“
    F103: å¤„ç†å™ªå£°æ–‡æ¡£ï¼Œæ”¹è¿›è´¨é‡
    â†“
Step 3: ä¼˜åŒ– (Tab4-5)
    â†“
    F104: å®šåˆ¶ä¸šåŠ¡æœ¯è¯­æ ‡ç­¾
    F105: å¯¹æ¯”ä¸åŒä¸»é¢˜ç‰¹å¾
    â†“
Step 4: éªŒè¯ (Tab6-7)
    â†“
    F106: å…³é”®è¯æœç´¢éªŒè¯
    F109: çœ‹çœŸå®æ„è§éªŒè¯è´¨é‡
    â†“
Step 5: è¾“å‡º (Tab8â†’P7)
    â†“
    F107: å¯¼å‡ºé«˜åˆ†è¾¨ç‡å›¾è¡¨å’ŒæŠ¥å‘Š
    ä¸Šä¼ åˆ°P7_è¯é¢˜çƒ­åº¦æ•æ„Ÿåº¦åˆ†æ
```

---

## ğŸ“Š é¡¹ç›®æ•°æ®ç»Ÿè®¡

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| **æ€»æ–‡æ¡£æ•°** | 2,297 |
| **æœ‰æ•ˆè¦†ç›–** | 99.3% |
| **éšè—ä¸»é¢˜æ•°** | 8-12 |
| **å¹³å‡ä¸»é¢˜å¤§å°** | ~192æ–‡æ¡£ |
| **å™ªå£°æ–‡æ¡£ç‡** | <1% |

## ğŸ”§ æŠ€æœ¯æ ˆ

- **æ¨¡å‹**: BERTopic (>=0.15.0)
- **åµŒå…¥æ¨¡å‹**: distiluse-base-multilingual-cased-v2
- **æ¡†æ¶**: Streamlit 9é¡µ
- **å¯¼å‡º**: Kaleido (å¯é€‰ï¼Œç”¨äºé™æ€å›¾)

## ğŸ“ æ ¸å¿ƒèƒ½åŠ›çŸ©é˜µ

| éœ€æ±‚ | F101 | F102 | F103 | F104 | F105 | F106 | F109 | F107 |
|------|------|------|------|------|------|------|------|------|
| ç†è§£å•æ–‡æ¡£ | âœ… | âœ… | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ |
| æ”¹è¿›æ•°æ®è´¨é‡ | âŒ | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ | âŒ |
| å®šåˆ¶æ ‡ç­¾ | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ |
| å¯¹æ¯”ä¸»é¢˜ | âŒ | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ | âœ… |
| å¿«é€Ÿæœç´¢ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ |
| éªŒè¯è´¨é‡ | âŒ | âœ… | âŒ | âŒ | âŒ | âœ… | âœ… | âŒ |
| ç”ŸæˆæŠ¥å‘Š | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… |

---

### æœ€æ–°æ›´æ–° (Phase 4-7)

âœ… Phase 4: F101-F103 å¯è§£é‡Šæ€§åˆ†æ  
âœ… Phase 5: F104-F106 æ ‡ç­¾+æœç´¢+å¯¹æ¯”  
âœ… Phase 6: F109 ä»£è¡¨æ–‡æ¡£æå–  
âœ… Phase 7: F107 è®ºæ–‡çº§å¯¼å‡º  

**æ€»æäº¤**: 4æ¬¡ | **æ–°å¢ä»£ç **: ~1500è¡Œ | **æ”¯æŒåŠŸèƒ½**: 8ä¸ªæ ¸å¿ƒ + 3ä¸ªæ‰©å±•

---

**æŠ€æœ¯è¦æ±‚**: 
- BERTopicå·²å¯ç”¨ `calculate_probabilities=True` âœ…
- å¯é€‰: `pip install kaleido` (ç”¨äºF107é™æ€å›¾å¯¼å‡º)
""")
