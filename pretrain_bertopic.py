"""
ç¦»çº¿é¢„è®­ç»ƒBERTopicæ¨¡å‹
åœ¨æœ¬åœ°è®­ç»ƒä¸€æ¬¡ï¼Œä¿å­˜æ¨¡å‹å’Œç»“æœï¼Œç„¶åä¸Šä¼ åˆ°äº‘ç«¯
è¿™æ ·P7é¡µé¢åŠ è½½æ—¶æ— éœ€é‡æ–°è®­ç»ƒï¼Œç›´æ¥ç§’å¼€
"""

import sys
import os
import pickle
import json
import pandas as pd
import numpy as np
from pathlib import Path

# æ·»åŠ streamlit_appåˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'streamlit_app'))

from utils.data_loader import load_analysis_data
from utils.bertopic_analyzer import get_bertopic_model

print("=" * 60)
print("ğŸš€ BERTopic ç¦»çº¿é¢„è®­ç»ƒè„šæœ¬")
print("=" * 60)
print()

# 1. åŠ è½½æ•°æ®
print("1ï¸âƒ£  åŠ è½½æ•°æ®...")
try:
    df = load_analysis_data()
    texts = df['source_text'].tolist()
    print(f"   âœ… å·²åŠ è½½ {len(texts)} æ¡èˆ†è®º")
except Exception as e:
    print(f"   âŒ åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

# 2. åˆå§‹åŒ–BERTopicæ¨¡å‹
print()
print("2ï¸âƒ£  åˆå§‹åŒ–BERTopicæ¨¡å‹...")
try:
    model = get_bertopic_model()
    if model is None:
        print("   âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
        sys.exit(1)
    print("   âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"   âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
    sys.exit(1)

# 3. è®­ç»ƒæ¨¡å‹
print()
print("3ï¸âƒ£  è®­ç»ƒBERTopicæ¨¡å‹ï¼ˆè¿™ä¼šèŠ±è´¹3-5åˆ†é’Ÿï¼‰...")
try:
    topics, probs = model.fit_transform(texts)
    print(f"   âœ… è®­ç»ƒå®Œæˆï¼å‘ç° {len(np.unique(topics))} ä¸ªä¸»é¢˜")
except Exception as e:
    print(f"   âŒ è®­ç»ƒå¤±è´¥: {e}")
    sys.exit(1)

# 4. ä¿å­˜æ¨¡å‹
print()
print("4ï¸âƒ£  ä¿å­˜æ¨¡å‹...")
model_dir = Path(__file__).parent / "streamlit_app" / "data" / "bertopic_model"
model_dir.mkdir(parents=True, exist_ok=True)

try:
    # ä¿å­˜BERTopicæ¨¡å‹
    model.save(str(model_dir))
    print(f"   âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
except Exception as e:
    print(f"   âŒ ä¿å­˜å¤±è´¥: {e}")
    sys.exit(1)

# 5. ä¿å­˜è¯é¢˜ç»“æœ
print()
print("5ï¸âƒ£  ä¿å­˜è¯é¢˜åˆ†æç»“æœ...")
try:
    results = {
        'topics': topics.tolist(),
        'probabilities': probs.tolist() if probs is not None else None,
        'topic_info': model.get_topic_info().to_dict(orient='records'),
        'num_topics': len(np.unique(topics)),
        'num_documents': len(texts)
    }
    
    result_file = model_dir / "topics_result.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"   âœ… ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
except Exception as e:
    print(f"   âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

# 6. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
print()
print("=" * 60)
print("ğŸ“Š é¢„è®­ç»ƒç»“æœç»Ÿè®¡")
print("=" * 60)
print()
print(f"æ€»æ–‡æ¡£æ•°: {len(texts)}")
print(f"å‘ç°çš„ä¸»é¢˜æ•°: {len(np.unique(topics))}")
print(f"å™ªå£°æ–‡æ¡£ (-1): {np.sum(topics == -1)}")
print()

# æ˜¾ç¤ºä¸»é¢˜ä¿¡æ¯
topic_info = model.get_topic_info()
print("ä¸»é¢˜åˆ†å¸ƒ:")
print(topic_info[['Topic', 'Count', 'Name']].to_string(index=False))
print()

print("=" * 60)
print("âœ… é¢„è®­ç»ƒå®Œæˆï¼")
print()
print("ğŸ“ åç»­æ­¥éª¤:")
print("   1. å°†ç”Ÿæˆçš„ streamlit_app/data/bertopic_model/ æ–‡ä»¶å¤¹ä¸Šä¼ åˆ°GitHub")
print("   2. ä¿®æ”¹P7é¡µé¢ï¼Œæ”¹ç”¨é¢„è®­ç»ƒæ¨¡å‹è€Œä¸æ˜¯æ¯æ¬¡é‡æ–°è®­ç»ƒ")
print("   3. P7é¡µé¢ä¼šç§’å¼€ï¼Œæ— éœ€ç­‰å¾…è®­ç»ƒ")
print()
print("=" * 60)
